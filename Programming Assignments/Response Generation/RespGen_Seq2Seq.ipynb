{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RespGen",
      "provenance": [],
      "collapsed_sections": [
        "Ws1Spfzewx6X",
        "7lkmLE5ju7ZD",
        "d5AJUVbmvBr8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikyk5tcEvFZg",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading and Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-WKEkwBTft4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "f3f60790-6615-40a5-8136-891d6a95c657"
      },
      "source": [
        "import os\n",
        "if \"aesthetix.py\" not in os.popen(\"ls\").read():\n",
        "  !wget https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Speech%20Recognition/ds_utils/aesthetix.py\n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "import aesthetix as at\n",
        "\n",
        "# Downloading movie_lines\n",
        "if \"movie_lines.txt\" not in os.popen(\"ls\").read():\n",
        "  !wget https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Response%20Generation/movie_lines.txt\n",
        "\n",
        "movielines = open(\"movie_lines.txt\", mode='r')\n",
        "print(movielines)\n",
        "lines = movielines.readlines()\n",
        "print(len(lines))\n",
        "\n",
        "def clean_str(_str):\n",
        "  _str = _str.strip()\n",
        "  _str = _str.lower()\n",
        "  _str = _str.replace(\".\", \"\")\n",
        "  _str = _str.replace(\",\", \"\")\n",
        "  _str = _str.replace(\"?\", \"\")\n",
        "  _str = _str.replace(\"!\", \"\")\n",
        "  _str = _str.replace(\":\", \"\")\n",
        "  _str = _str.replace(\"-\", \" \")\n",
        "  _str = _str.replace(\"_\", \" \")\n",
        "  _str = _str.replace(\"\\\\\", \"\")\n",
        "  _str = _str.replace(\"  \", \" \")\n",
        "  return _str\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-21 10:23:55--  https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Speech%20Recognition/ds_utils/aesthetix.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1212 (1.2K) [text/plain]\n",
            "Saving to: ‘aesthetix.py’\n",
            "\n",
            "\raesthetix.py          0%[                    ]       0  --.-KB/s               \raesthetix.py        100%[===================>]   1.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-21 10:23:55 (59.9 MB/s) - ‘aesthetix.py’ saved [1212/1212]\n",
            "\n",
            "--2020-06-21 10:24:00--  https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Response%20Generation/movie_lines.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34641921 (33M) [text/plain]\n",
            "Saving to: ‘movie_lines.txt’\n",
            "\n",
            "movie_lines.txt     100%[===================>]  33.04M  49.0MB/s    in 0.7s    \n",
            "\n",
            "2020-06-21 10:24:02 (49.0 MB/s) - ‘movie_lines.txt’ saved [34641921/34641921]\n",
            "\n",
            "<_io.TextIOWrapper name='movie_lines.txt' mode='r' encoding='UTF-8'>\n",
            "304713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWbYZKqToG6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4ddacce3-0d81-48d5-c8c1-97820fa9531d"
      },
      "source": [
        "sample_size = 20000\n",
        "cleanlines = []\n",
        "for i, line in enumerate(lines[:sample_size]):\n",
        "  at.progress_bar(\"Cleaning the lines\", i, len(lines[:sample_size]))\n",
        "  speaker, line = line.split('+++$+++ ')[-2:]\n",
        "  cleanlines.append([speaker.split(\" \")[0], line.split('\\n')[0]])\n",
        "\n",
        "cleanlines.reverse()\n",
        "cleanlines = np.array(cleanlines)\n",
        "for line in cleanlines[:10]:\n",
        "  print(line[0],\":\",line[1])\n",
        "\n",
        "\n",
        "# Forming the dataset \n",
        "response_data = []\n",
        "l = len(cleanlines)-1\n",
        "for i, line in enumerate(cleanlines[:-1]):\n",
        "  at.progress_bar(\"Generating Stimulus-Response Pairs\", i, l)\n",
        "  speaker, utterance = line\n",
        "  next_speaker, next_utterance = cleanlines[i+1]\n",
        "  if speaker is not next_speaker:\n",
        "    response_data.append(np.array([\"<start> \"+clean_str(utterance)+\" <end>\", \"<start> \"+clean_str(next_utterance)+\" <end>\"]))\n",
        "  \n",
        "response_data = np.array(response_data)\n",
        "print(response_data.shape)\n",
        "print(response_data[-10:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning the lines:[==============================](100.00%)  \n",
            "PRINCESS : Sir, I... come to beg you to confess all, and swear allegiance to the king, that he might show you mercy.\n",
            "WALLACE : Will he show mercy to my country? Will he take back his soldiers, and let us rule ourselves?\n",
            "PRINCESS : Mercy... is to die quickly. Perhaps even live in the Tower. In time, who knows what can happen, if you can only live.\n",
            "WALLACE : If I swear to him, then everything I am is dead already.\n",
            "PRINCESS : You will die! It will be awful!\n",
            "WALLACE : Every man dies. Not every man really lives.\n",
            "PRINCESS : Drink this! It will dull your pain.\n",
            "WALLACE : It will numb my wits, and I must have them all. If I'm senseless, or if I wail, then Longshanks will have broken me.\n",
            "PRINCESS : I can't bear the thought of your torture. Take it!\n",
            "NICOLETTE : When the king returns he will bury them in those new clothes. Scotland is in chaos. Your husband is secretly sending an army north.\n",
            "Generating Stimulus-Response Pairs:[==============================](98.41%)  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZzsXP40I3hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas as pd\n",
        "# a = pd.DataFrame({'Context': response_data[:, 0], 'Responses': response_data[:, 1]})\n",
        "# a.to_csv(\"Dat.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akxSWd_XybuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "d59853c7-a70d-420b-aa9a-fc940de77533"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "a = [len(s) for s in response_data[:,0]]\n",
        "# a_ = [s for s in response_data[:,0] if len(s)>2000]\n",
        "plt.plot(a)\n",
        "plt.show()\n",
        "print(np.mean(np.array(a)))\n",
        "print(\"Longest utterance : \", response_data[np.argmax(a), 0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "64.51767588379418\n",
            "Longest utterance :  <start> you've got penthouse playboy hustler etc nobody even considers them pornography anymore then there's mainstream hardcore triple x the difference is penetration that's hardcore that whole industry's up in the valley writers directors porn stars they're celebrities or they think they are they pump out 150 videos a week a week they've even got a porno academy awards america loves pornography anybody tells you they never use pornography they're lying somebody's buying those videos somebody's out there spending 900 million dollars a year on phone sex know what else it's only gonna get worse more and more you'll see perverse hardcore coming into the mainstream because that's evolution desensitization oh my god elvis presley's wiggling his hips how offensive nowadays mtv's showing girls dancing around in thong bikinis with their asses hanging out know what i mean for the porn addict big tits aren't big enough after a while they have to be the biggest tits ever some porn chicks are putting in breast implants bigger than your head literally soon playboy is gonna be penthouse penthouse'll be hustler hustler'll be hardcore and hardcore films'll be medical films people'll be jerking off to women laying around with open wounds there's nowhere else for it to go <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "374Iz8aIWnKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing the Data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "oov_token = \"<OOV>\"\n",
        "max_length = 25\n",
        "stimuli = response_data[:, 0]\n",
        "responses = response_data[:, 1]\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(stimuli)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "word_index['<start>'] = 0\n",
        "word_index['<end>'] = len(word_index)+1\n",
        "index_word = {word_index[word]:word for word in word_index}\n",
        "vocab_size = len(word_index)\n",
        "stimulus_sequences = tokenizer.texts_to_sequences(stimuli)\n",
        "response_sequences = tokenizer.texts_to_sequences(responses)\n",
        "\n",
        "padded_stimulus_sequences = pad_sequences(stimulus_sequences, maxlen = max_length ,padding = 'post', truncating = 'post')\n",
        "padded_response_sequences = pad_sequences(response_sequences, maxlen = max_length, padding = 'post', truncating = 'post')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYlQ5qIt3del",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c679cff-1324-46f8-c4e7-408fd139543e"
      },
      "source": [
        "index_word[1829]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'confess'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQG3-6YfwYv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "71ddf435-bb9f-48a6-ccbf-14adfe10d1ab"
      },
      "source": [
        "# Getting the embedding weights from pre-trained glove vectors\n",
        "embedding_dim = 100\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n",
        "    -O /tmp/glove.6B.100d.txt\n",
        "embeddings_index = {};\n",
        "with open('/tmp/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split();\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;\n",
        "\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-21 10:25:14--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 2404:6800:4008:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘/tmp/glove.6B.100d.txt’\n",
            "\n",
            "/tmp/glove.6B.100d. 100%[===================>] 331.04M  66.5MB/s    in 5.4s    \n",
            "\n",
            "2020-06-21 10:25:19 (61.4 MB/s) - ‘/tmp/glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_suV3kj_grY",
        "colab_type": "text"
      },
      "source": [
        "# Encoder-Decoder with Attention\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzH3Ym73U3oG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "024d8f6b-f9cd-4071-cb22-661dd96b46d6"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Bidirectional, Embedding, LSTM, RepeatVector, Concatenate, Dot, Activation, Input\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow_addons as tfa\n",
        "print(tf.__version__)\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm-JgxBABu2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 500\n",
        "BUFFER_SIZE = len(padded_response_sequences)\n",
        "num_dat_sets = 1\n",
        "steps_per_epoch = BUFFER_SIZE//(BATCH_SIZE*num_dat_sets)\n",
        "embedding_dims = 256\n",
        "rnn_units = 1024\n",
        "dense_units = 1024\n",
        "Dtype = tf.float32   #used to initialize DecoderCell Zero state\n",
        "Tx = max_length\n",
        "Ty = max_length"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G74NjgwrPr6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c36290ca-f166-49bc-be5d-26212e3bd547"
      },
      "source": [
        "BUFFER_SIZE"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boctA40PJomZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e517cc7-e6d9-4dce-da05-78e13cf6261d"
      },
      "source": [
        "# Initialising the dataset\n",
        "num_dats = BUFFER_SIZE // num_dat_sets\n",
        "datasets = [tf.data.Dataset.from_tensor_slices((padded_stimulus_sequences[i*num_dats:(i+1)*num_dats], padded_response_sequences[i*num_dats:(i+1)*num_dats])).shuffle(num_dats).batch(BATCH_SIZE, drop_remainder=True) for i in range(num_dat_sets) ]\n",
        "example_X, example_Y = next(iter(datasets[0]))\n",
        "print(example_X.shape) \n",
        "print(example_Y.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 25)\n",
            "(500, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfvCq9Ii_lZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderNet(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units, embeddings_matrix):\n",
        "    super(EncoderNet, self).__init__()\n",
        "    self.encoder_embedding = tf.keras.layers.Embedding(input_dim = vocab_size+1,\n",
        "                                                       output_dim = embedding_dim,\n",
        "                                                       weights = [embeddings_matrix], trainable = False)\n",
        "    self.encoder_rnnlayer = tf.keras.layers.LSTM(rnn_units,return_sequences = True, return_state = True)\n",
        "  \n",
        "# Decoder\n",
        "class DecoderNet(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units, embeddings_matrix):\n",
        "    super(DecoderNet, self).__init__()\n",
        "    self.decoder_embedding = tf.keras.layers.Embedding(input_dim = vocab_size+1,\n",
        "                                                       output_dim = embedding_dim, weights = [embeddings_matrix], trainable= False)\n",
        "    self.dense_layer = Dense(vocab_size)\n",
        "    self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)\n",
        "    #Sampler\n",
        "    self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "\n",
        "    self.attention_mechanism = self.build_attention_mechanism(dense_units, None, BATCH_SIZE*[Tx])\n",
        "    self.rnn_cell = self.build_rnn_cell(BATCH_SIZE)\n",
        "    self.decoder  = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler = self.sampler, output_layer = self.dense_layer)\n",
        "  \n",
        "  def build_attention_mechanism(self, units, memory, memory_sequence_length):\n",
        "    return tfa.seq2seq.LuongAttention(units, memory= memory, memory_sequence_length=memory_sequence_length)\n",
        "  \n",
        "  def build_rnn_cell(self, batch_size):\n",
        "    rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnncell, self.attention_mechanism, attention_layer_size = dense_units)\n",
        "    return rnn_cell\n",
        "  \n",
        "  def build_decoder_initial_state(self, batch_size, encoder_state, Dtype):\n",
        "    decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = batch_size, dtype = Dtype)\n",
        "    decoder_initial_state = decoder_initial_state.clone(cell_state =encoder_state)\n",
        "    return decoder_initial_state \n",
        "  \n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8sja6vcFDPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoderNet = EncoderNet(vocab_size, embedding_dim, rnn_units, embeddings_matrix)\n",
        "decoderNet = DecoderNet(vocab_size, embedding_dim, rnn_units, embeddings_matrix)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iavjoquAFYkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDW3OWXkGsc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(y_pred, y):\n",
        "  #shape of y [batch_size, ty]\n",
        "  #shape of y_pred [batch_size, Ty, output_vocab_size] \n",
        "  sparsecategoricalcrossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                                                reduction='none')\n",
        "  loss = sparsecategoricalcrossentropy(y_true=y, y_pred=y_pred)\n",
        "  #skip loss calculation for padding sequences i.e. y = 0 \n",
        "  \n",
        "  # mask the loss when padding sequence appears in the output sequence\n",
        "  mask = tf.logical_not(tf.math.equal(y,0))   #output 0 for y=0 else output 1\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss = mask* loss\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml6cE53VHubp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fc05681-d1b7-4d84-d003-196077961f66"
      },
      "source": [
        "decoderNet.attention_mechanism.memory_initialized"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySrcrQkKHw-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(input_batch, output_batch, encoder_initial_cell_state):\n",
        "  loss = 0\n",
        "  with tf.GradientTape() as tape:\n",
        "      encoder_emb_inp = encoderNet.encoder_embedding(input_batch)\n",
        "      a, a_tx, c_tx = encoderNet.encoder_rnnlayer(encoder_emb_inp, \n",
        "                                                      initial_state =encoder_initial_cell_state)\n",
        "\n",
        "      #[last step activations,last memory_state] of encoder passed as input to decoder Network\n",
        "      \n",
        "        \n",
        "      # Prepare correct Decoder input & output sequence data\n",
        "      decoder_input = output_batch[:,:-1] # ignore <end>\n",
        "      #compare logits with timestepped +1 version of decoder_input\n",
        "      decoder_output = output_batch[:,1:] #ignore <start>\n",
        "\n",
        "\n",
        "      # Decoder Embeddings\n",
        "      decoder_emb_inp = decoderNet.decoder_embedding(decoder_input)\n",
        "\n",
        "      #Setting up decoder memory from encoder output and Zero State for AttentionWrapperState\n",
        "      decoderNet.attention_mechanism.setup_memory(a)\n",
        "      decoder_initial_state = decoderNet.build_decoder_initial_state(BATCH_SIZE,\n",
        "                                                                          encoder_state=[a_tx, c_tx],\n",
        "                                                                          Dtype=tf.float32)\n",
        "      \n",
        "      #BasicDecoderOutput        \n",
        "      outputs, _, _ = decoderNet.decoder(decoder_emb_inp,initial_state=decoder_initial_state,\n",
        "                                              sequence_length=BATCH_SIZE*[Ty-1])\n",
        "\n",
        "      logits = outputs.rnn_output\n",
        "      #Calculate loss\n",
        "\n",
        "      loss = loss_function(logits, decoder_output)\n",
        "\n",
        "  #Returns the list of all layer variables / weights.\n",
        "  variables = encoderNet.trainable_variables + decoderNet.trainable_variables  \n",
        "  # differentiate loss wrt variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  #grads_and_vars – List of(gradient, variable) pairs.\n",
        "  grads_and_vars = zip(gradients,variables)\n",
        "  optimizer.apply_gradients(grads_and_vars)\n",
        "  return loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4xnqX8fIdUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dap58QdPInDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "checkpoint_path = \"ResponseModel/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "check_prefix = os.path.join(checkpoint_dir, \"checkpt\")\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optimizer = optimizer, encoderNet = encoderNet, decoderNet = decoderNet)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofLupLB7I2bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_initial_state():\n",
        "        return [tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units))]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTM4bUrmzfHr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90206557-4212-4cbd-d028-03c715228bea"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12954"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRkCAtTDI50H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_mod(dataset, epochs, history, verbose = True, save_check = False):\n",
        "  print(\"Training :\")\n",
        "  for i in range(1, epochs+1):\n",
        "    encoder_initial_cell_state = initialize_initial_state()\n",
        "    total_loss = 0.0\n",
        "    disp_loss = 0.0\n",
        "    for ( batch , (input_batch, output_batch)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "      if verbose : at.progress_bar(f\"Epoch {i}/{epochs}\", batch, steps_per_epoch, output_vals = {'Loss' : disp_loss})\n",
        "      batch_loss = train_step(input_batch, output_batch, encoder_initial_cell_state)\n",
        "      total_loss += batch_loss\n",
        "      disp_loss = total_loss/(max(batch, 1))\n",
        "    # Save checkpoint:\n",
        "    if save_check:\n",
        "      print(f\"Saving checkpoint at {checkpoint_path}\")\n",
        "      checkpoint.save(file_prefix=check_prefix)\n",
        "    history.append(disp_loss)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4CjHe8CLVpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss_history = []"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhkQ9gRYHRKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bdef1973-66c0-4716-c6b5-ef5366f2f464"
      },
      "source": [
        "fit_mod(datasets[0], 20, loss_history)\n",
        "plt.plot(loss_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training :\n",
            "Epoch 1/20:[==============================](100.00%)  Loss : 1.47 \n",
            "Epoch 2/20:[==============================](100.00%)  Loss : 1.41 \n",
            "Epoch 3/20:[=============================~](96.55%)  Loss : 1.34 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XS9KVmUsbva",
        "colab_type": "text"
      },
      "source": [
        "# Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVkx97hYPfK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04baba70-2149-48a9-e5d0-c280d7d4e7b0"
      },
      "source": [
        "# checkpoint.save(file_prefix = check_prefix)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResponseModel/checkpt-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wNKN_WJWuY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "91aca8e7-6929-4ac5-c48d-e32fd14691e7"
      },
      "source": [
        "# !zip -r  ResponseModel_s2s.zip ResponseModel"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: ResponseModel/ (stored 0%)\n",
            "  adding: ResponseModel/checkpt-1.data-00001-of-00002 (deflated 7%)\n",
            "  adding: ResponseModel/checkpt-1.data-00000-of-00002 (deflated 20%)\n",
            "  adding: ResponseModel/checkpoint (deflated 43%)\n",
            "  adding: ResponseModel/checkpt-1.index (deflated 67%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3cNwFGFYLms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0087c13b-2bdb-47d2-f5b7-2cae1c526eb3"
      },
      "source": [
        "import re\n",
        "[print(var) for var in tf.train.list_variables(\n",
        "    checkpoint_dir)]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('_CHECKPOINTABLE_OBJECT_GRAPH', [])\n",
            "('decoderNet/attention_mechanism/memory_layer/kernel/.ATTRIBUTES/VARIABLE_VALUE', [1024, 1024])\n",
            "('decoderNet/attention_mechanism/memory_layer/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [1024, 1024])\n",
            "('decoderNet/attention_mechanism/memory_layer/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [1024, 1024])\n",
            "('decoderNet/decoder_embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE', [12955, 100])\n",
            "('decoderNet/decoder_rnncell/bias/.ATTRIBUTES/VARIABLE_VALUE', [4096])\n",
            "('decoderNet/decoder_rnncell/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [4096])\n",
            "('decoderNet/decoder_rnncell/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [4096])\n",
            "('decoderNet/decoder_rnncell/kernel/.ATTRIBUTES/VARIABLE_VALUE', [1124, 4096])\n",
            "('decoderNet/decoder_rnncell/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [1124, 4096])\n",
            "('decoderNet/decoder_rnncell/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [1124, 4096])\n",
            "('decoderNet/decoder_rnncell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE', [1024, 4096])\n",
            "('decoderNet/decoder_rnncell/recurrent_kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [1024, 4096])\n",
            "('decoderNet/decoder_rnncell/recurrent_kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [1024, 4096])\n",
            "('decoderNet/dense_layer/bias/.ATTRIBUTES/VARIABLE_VALUE', [12954])\n",
            "('decoderNet/dense_layer/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [12954])\n",
            "('decoderNet/dense_layer/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [12954])\n",
            "('decoderNet/dense_layer/kernel/.ATTRIBUTES/VARIABLE_VALUE', [1024, 12954])\n",
            "('decoderNet/dense_layer/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [1024, 12954])\n",
            "('decoderNet/dense_layer/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [1024, 12954])\n",
            "('decoderNet/rnn_cell/_attention_layers/0/kernel/.ATTRIBUTES/VARIABLE_VALUE', [2048, 1024])\n",
            "('decoderNet/rnn_cell/_attention_layers/0/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [2048, 1024])\n",
            "('decoderNet/rnn_cell/_attention_layers/0/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [2048, 1024])\n",
            "('encoderNet/encoder_embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE', [12955, 100])\n",
            "('encoderNet/encoder_rnnlayer/cell/bias/.ATTRIBUTES/VARIABLE_VALUE', [4096])\n",
            "('encoderNet/encoder_rnnlayer/cell/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [4096])\n",
            "('encoderNet/encoder_rnnlayer/cell/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [4096])\n",
            "('encoderNet/encoder_rnnlayer/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE', [100, 4096])\n",
            "('encoderNet/encoder_rnnlayer/cell/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [100, 4096])\n",
            "('encoderNet/encoder_rnnlayer/cell/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [100, 4096])\n",
            "('encoderNet/encoder_rnnlayer/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE', [1024, 4096])\n",
            "('encoderNet/encoder_rnnlayer/cell/recurrent_kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [1024, 4096])\n",
            "('encoderNet/encoder_rnnlayer/cell/recurrent_kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [1024, 4096])\n",
            "('optimizer/beta_1/.ATTRIBUTES/VARIABLE_VALUE', [])\n",
            "('optimizer/beta_2/.ATTRIBUTES/VARIABLE_VALUE', [])\n",
            "('optimizer/decay/.ATTRIBUTES/VARIABLE_VALUE', [])\n",
            "('optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE', [])\n",
            "('optimizer/learning_rate/.ATTRIBUTES/VARIABLE_VALUE', [])\n",
            "('save_counter/.ATTRIBUTES/VARIABLE_VALUE', [])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pB7M02IYGy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "909c4036-b463-46db-e039-49bb333e7e0c"
      },
      "source": [
        "decoder_embedding_matrix = tf.train.load_variable(\n",
        "    checkpoint_dir, 'decoderNet/decoder_embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE')\n",
        "print(decoder_embedding_matrix.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12955, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G16aFSzexDuF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9b1b317a-2647-4541-9dbc-cc35f89ec18e"
      },
      "source": [
        "beam_width = 3\n",
        "\n",
        "sample_lines = [\"Hello\",\"Have you trained the Model?\", \"who are you\"]\n",
        "sample_lines = [clean_str(line) for line in sample_lines]\n",
        "\n",
        "sample_sequences  = tokenizer.texts_to_sequences(sample_lines)\n",
        "padded_sample_sequences = pad_sequences(sample_sequences, max_length, padding = \"post\", truncating = 'post')\n",
        "\n",
        "inp = tf.convert_to_tensor(padded_sample_sequences, dtype = Dtype)\n",
        "inference_batch_size = len(sample_lines)\n",
        "\n",
        "encoder_initial_cell_state = [tf.zeros((inference_batch_size, rnn_units)),\n",
        "                              tf.zeros((inference_batch_size, rnn_units))]\n",
        "encoder_emb_inp = encoderNet.encoder_embedding(inp)\n",
        "a, a_tx, c_tx = encoderNet.encoder_rnnlayer(encoder_emb_inp,\n",
        "                                                initial_state =encoder_initial_cell_state)\n",
        "\n",
        "start_tokens = tf.fill([inference_batch_size],word_index['<start>'])\n",
        "#print(start_tokens)\n",
        "end_token = word_index['<end>']\n",
        "\n",
        "\n",
        "\n",
        "decoder_input = tf.expand_dims([word_index['<start>']]* inference_batch_size,1)\n",
        "decoder_emb_inp = decoderNet.decoder_embedding(decoder_input)\n",
        "\n",
        "\n",
        "#From official documentation\n",
        "#NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
        "\n",
        "#The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
        "#The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
        "#The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
        "encoder_memory = tfa.seq2seq.tile_batch(a, beam_width)\n",
        "decoderNet.attention_mechanism.setup_memory(encoder_memory)\n",
        "print(\"beam_with * [batch_size, Tx, rnn_units] :  3 * [2, Tx, rnn_units]] :\", encoder_memory.shape)\n",
        "#set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
        "decoder_initial_state = decoderNet.rnn_cell.get_initial_state(batch_size = inference_batch_size* beam_width,dtype = Dtype)\n",
        "encoder_state = tfa.seq2seq.tile_batch([a_tx, c_tx], multiplier=beam_width)\n",
        "decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state) \n",
        "\n",
        "decoder_instance = tfa.seq2seq.BeamSearchDecoder(decoderNet.rnn_cell,beam_width=beam_width,\n",
        "                                                 output_layer=decoderNet.dense_layer)\n",
        "\n",
        "\n",
        "# Since we do not know the target sequence lengths in advance, we use maximum_iterations to limit the translation lengths.\n",
        "# One heuristic is to decode up to two times the source sentence lengths.\n",
        "maximum_iterations = tf.round(tf.reduce_max(Tx) * 2)\n",
        "\n",
        "#initialize inference decoder\n",
        "\n",
        "(first_finished, first_inputs,first_state) = decoder_instance.initialize(decoder_embedding_matrix,\n",
        "                             start_tokens = start_tokens,\n",
        "                             end_token=end_token,\n",
        "                             initial_state = decoder_initial_state)\n",
        "#print( first_finished.shape)\n",
        "print(\"\\nfirst_inputs returns the same decoder_input i.e. embedding of  <start> :\",first_inputs.shape)\n",
        "\n",
        "inputs = first_inputs\n",
        "state = first_state  \n",
        "predictions = np.empty((inference_batch_size, beam_width,0), dtype = np.int32)\n",
        "beam_scores =  np.empty((inference_batch_size, beam_width,0), dtype = np.float32)                                                                            \n",
        "for j in range(maximum_iterations):\n",
        "    beam_search_outputs, next_state, next_inputs, finished = decoder_instance.step(j,inputs,state)\n",
        "    inputs = next_inputs\n",
        "    state = next_state\n",
        "    outputs = np.expand_dims(beam_search_outputs.predicted_ids,axis = -1)\n",
        "    scores = np.expand_dims(beam_search_outputs.scores,axis = -1)\n",
        "    predictions = np.append(predictions, outputs, axis = -1)\n",
        "    beam_scores = np.append(beam_scores, scores, axis = -1)\n",
        "print(predictions.shape) \n",
        "print(beam_scores.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beam_with * [batch_size, Tx, rnn_units] :  3 * [2, Tx, rnn_units]] : (9, 25, 1024)\n",
            "\n",
            "first_inputs returns the same decoder_input i.e. embedding of  <start> : (3, 3, 100)\n",
            "(3, 3, 50)\n",
            "(3, 3, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD-mRHiTyeOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "67e20b8d-5cfb-4942-a2ad-c734a46d49de"
      },
      "source": [
        "import itertools\n",
        "print(\"Stimuli:\")\n",
        "for line in sample_lines :\n",
        "  print(line)\n",
        "print(\"Responses\")\n",
        "for i in range(len(predictions)):\n",
        "  output_beams_per_sample = predictions[i,:,:]\n",
        "  score_beams_per_sample = beam_scores[i,:,:]\n",
        "  for beam, score in zip(output_beams_per_sample,score_beams_per_sample) :\n",
        "    seq = list(itertools.takewhile( lambda index: index !=2, beam))\n",
        "    score_indexes = np.arange(len(seq))\n",
        "    beam_score = score[score_indexes].sum()/len(seq)\n",
        "    print(\" \".join( [index_word[w] for w in seq]), \" beam score: \", beam_score)\n",
        "  print()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stimuli:\n",
            "hello\n",
            "have you trained the model\n",
            "who are you\n",
            "Responses\n",
            "you end end the end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end  beam score:  -33.40548095703125\n",
            "i know what end north toward is the the the now the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the  beam score:  -34.5466455078125\n",
            "yes didn't i i first is the and and and the now snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow snow  beam score:  -34.98837158203125\n",
            "\n",
            "i end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end  beam score:  -35.684638671875\n",
            "yes know i i i end end end the know end the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the  beam score:  -37.17215087890625\n",
            "you i the the point i i i i north the end then then then then on the on on on on on on on on on on on on on on on on and and and and and and and and and and and and and and and and  beam score:  -37.55284912109375\n",
            "\n",
            "i end end end the end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end  beam score:  -32.16031982421875\n",
            "you know i i end afternoon i i the corner end end end the the the the the the the the the and the and the and the the the the the the the the the the the the the the the the the the the the the the the  beam score:  -33.7143115234375\n",
            "yes know what the i i end on i i i the the the bridge end end end the and and and the and the and the and and and and and and and and and and and and and and and and and and and and and and and  beam score:  -33.9460400390625\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp75mjyk2CzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}