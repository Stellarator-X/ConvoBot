{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResponseGeneration",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdC2J6P5rkJzU+WgZbeW8U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BctoPGKXmjfx",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rirUTulY3wQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bde3161a-f1c7-4173-dcb3-510bdeb68dd8"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Speech%20Recognition/ds_utils/aesthetix.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-17 21:09:34--  https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Speech%20Recognition/ds_utils/aesthetix.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1212 (1.2K) [text/plain]\n",
            "Saving to: ‘aesthetix.py.5’\n",
            "\n",
            "\raesthetix.py.5        0%[                    ]       0  --.-KB/s               \raesthetix.py.5      100%[===================>]   1.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-17 21:09:34 (65.6 MB/s) - ‘aesthetix.py.5’ saved [1212/1212]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM1_bpbpZA8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "import aesthetix as at"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rrPXDRVdYPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d4cb7a74-9c81-4522-f1bd-9fe33dd91a05"
      },
      "source": [
        "# Downloading movie_lines\n",
        "!wget https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Response%20Generation/movie_lines.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-17 21:09:38--  https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Response%20Generation/movie_lines.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34641921 (33M) [text/plain]\n",
            "Saving to: ‘movie_lines.txt.5’\n",
            "\n",
            "movie_lines.txt.5   100%[===================>]  33.04M   133MB/s    in 0.2s    \n",
            "\n",
            "2020-06-17 21:09:39 (133 MB/s) - ‘movie_lines.txt.5’ saved [34641921/34641921]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmPWdro0wiiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "637e766f-9a5d-4ebd-985d-47d0ee120213"
      },
      "source": [
        "movielines = open(\"movie_lines.txt\", mode='r')\n",
        "print(movielines)\n",
        "lines = movielines.readlines()\n",
        "print(len(lines))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_io.TextIOWrapper name='movie_lines.txt' mode='r' encoding='UTF-8'>\n",
            "304713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKm3kb-A1xyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "932efeb4-72cc-4870-f7e4-8891ba0b2763"
      },
      "source": [
        "for line in lines[-10:]:\n",
        "  print(line)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L666262 +++$+++ u9031 +++$+++ m616 +++$+++ MELVILL +++$+++ Lighting COGHILL' 5 cigar: Our good Colonel Dumford scored quite a coup with the Sikali Horse.\n",
            "\n",
            "L666522 +++$+++ u9034 +++$+++ m616 +++$+++ VEREKER +++$+++ So far only their scouts. But we have had reports of a small Impi farther north, over there. \n",
            "\n",
            "L666521 +++$+++ u9030 +++$+++ m616 +++$+++ DURNFORD +++$+++ And I assure you, you do not In fact I'd be obliged for your best advice. What have your scouts seen?\n",
            "\n",
            "L666520 +++$+++ u9034 +++$+++ m616 +++$+++ VEREKER +++$+++ Well I assure you, Sir, I have no desire to create difficulties. 45\n",
            "\n",
            "L666372 +++$+++ u9034 +++$+++ m616 +++$+++ VEREKER +++$+++ I think Chelmsford wants a good man on the border Why he fears a flanking attack and requires a steady Commander in reserve.\n",
            "\n",
            "L666371 +++$+++ u9030 +++$+++ m616 +++$+++ DURNFORD +++$+++ Lord Chelmsford seems to want me to stay back with my Basutos.\n",
            "\n",
            "L666370 +++$+++ u9034 +++$+++ m616 +++$+++ VEREKER +++$+++ I'm to take the Sikali with the main column to the river\n",
            "\n",
            "L666369 +++$+++ u9030 +++$+++ m616 +++$+++ DURNFORD +++$+++ Your orders, Mr Vereker?\n",
            "\n",
            "L666257 +++$+++ u9030 +++$+++ m616 +++$+++ DURNFORD +++$+++ Good ones, yes, Mr Vereker. Gentlemen who can ride and shoot\n",
            "\n",
            "L666256 +++$+++ u9034 +++$+++ m616 +++$+++ VEREKER +++$+++ Colonel Durnford... William Vereker. I hear you 've been seeking Officers?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWbYZKqToG6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "79d31ee5-5b6a-4b1f-95a8-e364e19511dc"
      },
      "source": [
        "sample_size = 30000\n",
        "cleanlines = []\n",
        "for i, line in enumerate(lines[:sample_size]):\n",
        "  at.progress_bar(\"Cleaning the lines\", i, len(lines[:sample_size]))\n",
        "  speaker, line = line.split('+++$+++ ')[-2:]\n",
        "  cleanlines.append([speaker.split(\" \")[0], line.split('\\n')[0]])\n",
        "\n",
        "cleanlines.reverse()\n",
        "cleanlines = np.array(cleanlines)\n",
        "for line in cleanlines[:10]:\n",
        "  print(line[0],\":\",line[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning the lines:[==============================](100.00%)  \n",
            "BOZO : Yeah, maybe.\n",
            "HEROINE : Get something on that.\n",
            "BOZO : Where the hell are we going to go then, Billy Jack!?\n",
            "HEROINE : There's a bomb shelter over in Durant, by the IGA, on First. You all know where that is?\n",
            "BOZO : Welcome back.\n",
            "ROADIE : F-f-fuck you.\n",
            "ROADIE : They were all over the place.\n",
            "BOZO : You smell like ass!\n",
            "ROADIE : Look, the armed surround the unarmed in a circle and we move as a tight group. Those that can shoot, protect the rest to his ride.\n",
            "BOZO : Hey, when this plan completely goes to shit, what are ya gonna do?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydf-f2aklFG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_str(_str):\n",
        "        _str = _str.strip()\n",
        "        _str = _str.lower()\n",
        "        _str = _str.replace(\".\", \"\")\n",
        "        _str = _str.replace(\",\", \"\")\n",
        "        _str = _str.replace(\"?\", \"\")\n",
        "        _str = _str.replace(\"!\", \"\")\n",
        "        _str = _str.replace(\":\", \"\")\n",
        "        _str = _str.replace(\"-\", \" \")\n",
        "        _str = _str.replace(\"_\", \" \")\n",
        "        _str = _str.replace(\"\\\\\", \"\")\n",
        "        _str = _str.replace(\"  \", \" \")\n",
        "        return _str"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRKx3cY0U1w1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "38e6044b-dd84-4f02-f9a4-43486d159b57"
      },
      "source": [
        "# Forming the dataset \n",
        "response_data = []\n",
        "l = len(cleanlines)-1\n",
        "for i, line in enumerate(cleanlines[:-1]):\n",
        "  at.progress_bar(\"Generating Stimulus-Response Pairs\", i, l)\n",
        "  speaker, utterance = line\n",
        "  next_speaker, next_utterance = cleanlines[i+1]\n",
        "  if speaker is not next_speaker:\n",
        "    response_data.append(np.array([clean_str(utterance.lower()), clean_str(next_utterance.lower())]))\n",
        "  \n",
        "response_data = np.array(response_data)\n",
        "print(response_data.shape)\n",
        "print(response_data[-10:])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating Stimulus-Response Pairs:[==============================](98.86%)  (29999, 2)\n",
            "[['the \"real you\"' 'like my fear of wearing pastels']\n",
            " ['like my fear of wearing pastels'\n",
            "  'i\\'m kidding you know how sometimes you just become this \"persona\" and you don\\'t know how to quit']\n",
            " ['i\\'m kidding you know how sometimes you just become this \"persona\" and you don\\'t know how to quit'\n",
            "  'no']\n",
            " ['no' \"okay  you're gonna need to learn how to lie\"]\n",
            " [\"okay  you're gonna need to learn how to lie\" 'wow']\n",
            " ['wow' \"let's go\"]\n",
            " [\"let's go\" 'she okay']\n",
            " ['she okay' 'i hope so']\n",
            " ['i hope so' 'they do to']\n",
            " ['they do to' 'they do not']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akxSWd_XybuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "6a7115c0-99fc-4ab8-fd6f-740cfc3b3c8d"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "a = [len(s) for s in response_data[:,0]]\n",
        "a_ = [s for s in response_data[:,0] if len(s)>2000]\n",
        "plt.plot(a)\n",
        "plt.show()\n",
        "print(np.mean(np.array(a)))\n",
        "print(\"Longest utterance : \", a_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "51.615920530684356\n",
            "Longest utterance :  [\"shit o dear that's enough to make me asthmatic the nerve of those twits what do they know about female odor don't interrupt here's my concept my ranch out west it's a beauty ranch oh it's got a few head of cattle for atmosphere and tax purposes but it's a beauty ranch a place where unhappy women  divorcees and widows mainly  can go to lose weight remove wrinkles change their hair styles and pretty themselves up for the next disappointment my ranch is named the rubber rose after the rubber rose douche bag my own invention and bless its little red bladder the most popular douche bag in the world so get this it's on the migratory flight path of the whooping cranes the last flock of wild whooping cranes left in existence well these cranes stop off at my little pond  siwash lake it's called  twice a year autumn and spring and spend a few days each time resting up eating doing whatever whooping cranes do i've never seen them understand but i hear they're magnificent very big specimens  i mean huge mothers  and white as snow to coin a phrase except for black tips on their wings and tail feathers and bright red heads now whooping cranes in case you didn't know it are noted for their mating dance it's just the wildest show in nature it's probably the reason why birdwatching used to be so popular with old maids and deacons picture these rare beautiful gigantic birds in full dance  leaping six feet off the mud arching their backs flapping their wings strutting low to the ground dears it's overwhelming and picture the birds doing their sex dance on tv right there on the home screen creation's most elaborate sex ritual  yet clean and pure enough to suit the pope with lovely sissy hankshaw in the foreground in a white gown red hood attached and big feathery sleeves trimmed in black in a very subdued imitation of the female whooping crane she dance/walks over to a large nest in which there sits a can of yoni yum and a can of dew off camera a string quartet is playing debussy a sensuous voice is reading a few poetic lines about courtship and love are you starting to get it doesn't it make the hair on your neck stand up and applaud my very goodness gracious grandiose lyrical erotic and girl scout oriented; you can't top it i've hired a crew of experts from walt disney studios the best wildlife cinematographers around you're my eternal favorite princess grace herself couldn't be better not even if she had your personality which she doesn't; anyway dear i'm out of photography now and into water colors ah how circuitous conversation is we're back at the beginning the exact man i've wanted you to meet is my artist the watercolorist\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "374Iz8aIWnKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing the Data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "oov_token = \"<OOV>\"\n",
        "max_length = 300\n",
        "\n",
        "stimuli = response_data[:, 0]\n",
        "responses = response_data[:, 1]\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(stimuli)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)\n",
        "\n",
        "stimulus_sequences = tokenizer.texts_to_sequences(stimuli)\n",
        "response_sequences = tokenizer.texts_to_sequences(responses)\n",
        "\n",
        "padded_stimulus_sequences = pad_sequences(stimulus_sequences, maxlen = max_length ,padding = 'post', truncating = 'post')\n",
        "padded_response_sequences = pad_sequences(response_sequences, maxlen = max_length, padding = 'post', truncating = 'post')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nniAEr6mrxb",
        "colab_type": "text"
      },
      "source": [
        "# Seq2Seq Attention Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlajpokaVmzt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae7d4634-edce-423b-fbc9-650f5e2ac6d6"
      },
      "source": [
        "from keras.layers import Dense, GRU, Bidirectional, Concatenate, Permute, Dot \n",
        "from keras.layers import RepeatVector, Activation, Lambda, Input, Multiply, Embedding\n",
        "from keras.optimizers import Adam \n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "import keras.backend as K"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pKIwu2ywWZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ea986743-101a-46f9-e30b-f90bc87ea55c"
      },
      "source": [
        "# Getting the embeddings matrix from trained Glove Embeddings\n",
        "embedding_dim = 100\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n",
        "    -O /tmp/glove.6B.100d.txt\n",
        "embeddings_index = {};\n",
        "with open('/tmp/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split();\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;\n",
        "\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-17 21:11:26--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.206.128, 2a00:1450:400c:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.206.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘/tmp/glove.6B.100d.txt’\n",
            "\n",
            "\r/tmp/glove.6B.100d.   0%[                    ]       0  --.-KB/s               \r/tmp/glove.6B.100d.   1%[                    ]   4.01M  16.6MB/s               \r/tmp/glove.6B.100d.   2%[                    ]   8.01M  14.5MB/s               \r/tmp/glove.6B.100d.   8%[>                   ]  26.54M  35.2MB/s               \r/tmp/glove.6B.100d.  15%[==>                 ]  52.55M  55.1MB/s               \r/tmp/glove.6B.100d.  24%[===>                ]  79.90M  69.3MB/s               \r/tmp/glove.6B.100d.  29%[====>               ]  96.01M  57.1MB/s               \r/tmp/glove.6B.100d.  37%[======>             ] 125.34M  66.6MB/s               \r/tmp/glove.6B.100d.  47%[========>           ] 158.17M  76.0MB/s               \r/tmp/glove.6B.100d.  52%[=========>          ] 175.14M  76.8MB/s               \r/tmp/glove.6B.100d.  59%[==========>         ] 197.49M  79.6MB/s               \r/tmp/glove.6B.100d.  67%[============>       ] 222.02M  82.8MB/s               \r/tmp/glove.6B.100d.  74%[=============>      ] 246.82M  85.7MB/s               \r/tmp/glove.6B.100d.  74%[=============>      ] 248.01M  74.5MB/s    eta 1s     \r/tmp/glove.6B.100d.  79%[==============>     ] 264.16M  74.8MB/s    eta 1s     \r/tmp/glove.6B.100d.  86%[================>   ] 286.56M  76.8MB/s    eta 1s     \r/tmp/glove.6B.100d.  91%[=================>  ] 304.01M  74.1MB/s    eta 1s     \r/tmp/glove.6B.100d.  97%[==================> ] 323.45M  78.5MB/s    eta 1s     \r/tmp/glove.6B.100d. 100%[===================>] 331.04M  78.9MB/s    in 4.4s    \n",
            "\n",
            "2020-06-17 21:11:31 (75.5 MB/s) - ‘/tmp/glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g32tQ-ujWhPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shared Layers\n",
        "Repeator = RepeatVector(300)\n",
        "Concatenator = Concatenate()\n",
        "Dense1 = Dense(10, activation = 'tanh')\n",
        "Dense2 = Dense(1, activation = 'relu')\n",
        "Activator = Activation(lambda x:K.softmax(x, axis = 1), name = 'Attention_params')\n",
        "DotLayer = Dot(axes=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hurJFNjJVrdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AttentionLayer(a, s_prev):\n",
        "  s_prev = Repeator(s_prev)\n",
        "  concat = Concatenator([a, s_prev])\n",
        "  e = Dense1(concat)\n",
        "  e = Dense2(e)\n",
        "  alphas = Activator(e)\n",
        "  context = DotLayer([alphas, a])\n",
        "  return context"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm0Vc6RqYR5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_attention_units = 200\n",
        "post_attention_units = 400\n",
        "outLength = 500\n",
        "\n",
        "PostAttentionGru = GRU(post_attention_units, return_state=True)\n",
        "OutputLayer = Dense(outLength, activation = 'softmax')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FamKGNfDZSQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResponseModel(maxlen, pre_attention_units, post_attention_units, vocab_size):\n",
        "  \"\"\"\n",
        "    Parameters:\n",
        "      maxlen : maxlen\n",
        "      pre_attention_units : hidden state size of the BiGRU\n",
        "      post_attention_units : hidden state size of the post-attention GRU\n",
        "      vocab_size -- size of the python dictionary \"human_vocab\"\n",
        "    Returns:\n",
        "      ResponseModel instance  \n",
        "  \"\"\"\n",
        "  X = Input(shape=(maxlen,))\n",
        "  s0 = Input(shape = (post_attention_units,), name = 's0')\n",
        "  c0 = Input(shape = (post_attention_units,), name = 'c0')\n",
        "  s=s0\n",
        "  c=c0\n",
        "\n",
        "  outputs = []\n",
        "\n",
        "  X_emb = Embedding(vocab_size+1, embedding_dim, weights = [embeddings_matrix], trainable = False, input_length=maxlen)(X)\n",
        "  a = Bidirectional(GRU(units = pre_attention_units, return_sequences=True))(X_emb)\n",
        "\n",
        "  for t in range(maxlen):\n",
        "    context = AttentionLayer(a, s)\n",
        "    s, _ ,c = PostAttentionGru(context, initial_state=[s, c])\n",
        "    out = OutputLayer(s)\n",
        "    outputs.append(out)\n",
        "  \n",
        "  model = Model(inputs = [X, s0, c0], outputs = outputs)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMsGFhxLbymF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7bd0c73d-d97d-40a0-8ed5-23125cc89b8b"
      },
      "source": [
        "randommod = ResponseModel(max_length, 200, 400, vocab_size)\n",
        "randommod.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1c31d621e936>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandommod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResponseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrandommod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-4b3cad6f6580>\u001b[0m in \u001b[0;36mResponseModel\u001b[0;34m(maxlen, pre_attention_units, post_attention_units, vocab_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPostAttentionGru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOutputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'constants'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'constants'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;34m'`cell.state_size`. Received `state_spec`={}; '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                     \u001b[0;34m'however `cell.state_size` is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                     '{}'.format(self.state_spec, self.cell.state_size))\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             self.state_spec = [InputSpec(shape=(None, dim))\n",
            "\u001b[0;31mValueError\u001b[0m: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=[InputSpec(shape=(None, 400), ndim=2), InputSpec(shape=(None, 400), ndim=2)]; however `cell.state_size` is 400"
          ]
        }
      ]
    }
  ]
}