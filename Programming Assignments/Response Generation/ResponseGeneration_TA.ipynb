{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResponseGeneration_tf_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "P6HGYBDPu9GK",
        "JZ19z71Guz4R"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6HGYBDPu9GK",
        "colab_type": "text"
      },
      "source": [
        "# Datagen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppc9JeXJFj1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c8a546a-6290-46f3-e5e9-b7c8e8606080"
      },
      "source": [
        "!pip install aesthetix"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aesthetix in /usr/local/lib/python3.6/dist-packages (0.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mu_225xS3Aj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2fe111a-4a7e-4978-968d-35ece0f05b97"
      },
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-IzvHNAVhEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "acae314c-4a25-40ad-aef8-9d06dbd5f8c8"
      },
      "source": [
        "import os\n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "import aesthetix as at\n",
        "\n",
        "# Downloading movie_lines\n",
        "if \"movie_lines.txt\" not in os.popen(\"ls\").read():\n",
        "  !wget https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Response%20Generation/movie_lines.txt\n",
        "\n",
        "movielines = open(\"movie_lines.txt\", mode='r')\n",
        "print(movielines)\n",
        "lines = movielines.readlines()\n",
        "print(len(lines))\n",
        "\n",
        "def clean_str(_str):\n",
        "  _str = _str.strip()\n",
        "  _str = _str.lower()\n",
        "  _str = _str.replace(\".\", \"\")\n",
        "  _str = _str.replace(\",\", \"\")\n",
        "  _str = _str.replace(\"?\", \"\")\n",
        "  _str = _str.replace(\"!\", \"\")\n",
        "  _str = _str.replace(\":\", \"\")\n",
        "  _str = _str.replace(\">\", \"\")\n",
        "  _str = _str.replace(\"<\", \"\")\n",
        "  _str = _str.replace(\"-\", \" \")\n",
        "  _str = _str.replace(\"_\", \" \")\n",
        "  _str = _str.replace(\"\\\\\", \"\")\n",
        "  _str = _str.replace(\"  \", \" \")\n",
        "  return _str\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_io.TextIOWrapper name='movie_lines.txt' mode='r' encoding='UTF-8'>\n",
            "304713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUKBdeJXLBP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "6790ecfc-0601-4d91-f609-c040cfc154d4"
      },
      "source": [
        "sample_size = 20000\n",
        "cleanlines = []\n",
        "for i, line in enumerate(lines[:sample_size]):\n",
        "  at.progress_bar(\"Cleaning the lines\", i, len(lines[:sample_size]))\n",
        "  speaker, line = line.split('+++$+++ ')[-2:]\n",
        "  cleanlines.append([speaker.split(\" \")[0], line.split('\\n')[0]])\n",
        "\n",
        "cleanlines.reverse()\n",
        "cleanlines = np.array(cleanlines)\n",
        "for line in cleanlines[:10]:\n",
        "  print(line[0],\":\",line[1])\n",
        "\n",
        "\n",
        "# Forming the dataset \n",
        "response_data = []\n",
        "l = len(cleanlines)-1\n",
        "for i, line in enumerate(cleanlines[:-1]):\n",
        "  at.progress_bar(\"Generating Stimulus-Response Pairs\", i, l)\n",
        "  speaker, utterance = line\n",
        "  next_speaker, next_utterance = cleanlines[i+1]\n",
        "  if speaker is not next_speaker:\n",
        "    response_data.append(np.array([\"<start> \"+clean_str(utterance)+\" <end>\", \"<start> \"+clean_str(next_utterance)+\" <end>\"]))\n",
        "  \n",
        "response_data = np.array(response_data)\n",
        "print(response_data.shape)\n",
        "print(response_data[-10:])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning the lines:[==============================](100.00%)  \n",
            "PRINCESS : Sir, I... come to beg you to confess all, and swear allegiance to the king, that he might show you mercy.\n",
            "WALLACE : Will he show mercy to my country? Will he take back his soldiers, and let us rule ourselves?\n",
            "PRINCESS : Mercy... is to die quickly. Perhaps even live in the Tower. In time, who knows what can happen, if you can only live.\n",
            "WALLACE : If I swear to him, then everything I am is dead already.\n",
            "PRINCESS : You will die! It will be awful!\n",
            "WALLACE : Every man dies. Not every man really lives.\n",
            "PRINCESS : Drink this! It will dull your pain.\n",
            "WALLACE : It will numb my wits, and I must have them all. If I'm senseless, or if I wail, then Longshanks will have broken me.\n",
            "PRINCESS : I can't bear the thought of your torture. Take it!\n",
            "NICOLETTE : When the king returns he will bury them in those new clothes. Scotland is in chaos. Your husband is secretly sending an army north.\n",
            "Generating Stimulus-Response Pairs:[==============================](100.00%)  \n",
            "(19999, 2)\n",
            "[['<start> the \"real you\" <end>'\n",
            "  '<start> like my fear of wearing pastels <end>']\n",
            " ['<start> like my fear of wearing pastels <end>'\n",
            "  '<start> i\\'m kidding you know how sometimes you just become this \"persona\" and you don\\'t know how to quit <end>']\n",
            " ['<start> i\\'m kidding you know how sometimes you just become this \"persona\" and you don\\'t know how to quit <end>'\n",
            "  '<start> no <end>']\n",
            " ['<start> no <end>'\n",
            "  \"<start> okay  you're gonna need to learn how to lie <end>\"]\n",
            " [\"<start> okay  you're gonna need to learn how to lie <end>\"\n",
            "  '<start> wow <end>']\n",
            " ['<start> wow <end>' \"<start> let's go <end>\"]\n",
            " [\"<start> let's go <end>\" '<start> she okay <end>']\n",
            " ['<start> she okay <end>' '<start> i hope so <end>']\n",
            " ['<start> i hope so <end>' '<start> they do to <end>']\n",
            " ['<start> they do to <end>' '<start> they do not <end>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZQK9q-1LL2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "6a9519df-a836-4355-8788-56f7dd73a555"
      },
      "source": [
        "a = [len(s) for s in response_data[:,0]]\n",
        "plt.plot(a)\n",
        "plt.xlabel(\"Utterances\")\n",
        "plt.ylabel(\"Length\")\n",
        "plt.show()\n",
        "print(np.mean(np.array(a)))\n",
        "print(\"Longest utterance : \", response_data[np.argmax(a), 0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "64.50467523376169\n",
            "Longest utterance :  <start> you've got penthouse playboy hustler etc nobody even considers them pornography anymore then there's mainstream hardcore triple x the difference is penetration that's hardcore that whole industry's up in the valley writers directors porn stars they're celebrities or they think they are they pump out 150 videos a week a week they've even got a porno academy awards america loves pornography anybody tells you they never use pornography they're lying somebody's buying those videos somebody's out there spending 900 million dollars a year on phone sex know what else it's only gonna get worse more and more you'll see perverse hardcore coming into the mainstream because that's evolution desensitization oh my god elvis presley's wiggling his hips how offensive nowadays mtv's showing girls dancing around in thong bikinis with their asses hanging out know what i mean for the porn addict big tits aren't big enough after a while they have to be the biggest tits ever some porn chicks are putting in breast implants bigger than your head literally soon playboy is gonna be penthouse penthouse'll be hustler hustler'll be hardcore and hardcore films'll be medical films people'll be jerking off to women laying around with open wounds there's nowhere else for it to go <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZW-mSq2ZKfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing the Data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "oov_token = \"<OOV>\"\n",
        "max_length = 25\n",
        "stimuli = response_data[:, 0]\n",
        "responses = response_data[:, 1]\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_token, filters = \"\")\n",
        "tokenizer.fit_on_texts(stimuli)\n",
        "# with open(\"Tokens.txt\") as file:\n",
        "#   json_string = file.read()\n",
        "# tokenizer = tokenizer_from_json(json_string)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "index_word = {word_index[word]:word for word in word_index}\n",
        "vocab_size = len(word_index)\n",
        "stimulus_sequences = tokenizer.texts_to_sequences(stimuli)\n",
        "response_sequences = tokenizer.texts_to_sequences(responses)\n",
        "\n",
        "padded_stimulus_sequences = pad_sequences(stimulus_sequences, maxlen = max_length ,padding = 'post', truncating = 'post')\n",
        "padded_response_sequences = pad_sequences(response_sequences, maxlen = max_length, padding = 'post', truncating = 'post')\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX2Wnd7Re4Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_string = tokenizer.to_json()\n",
        "with open(\"Tokens.txt\", \"w\") as file:\n",
        "  file.write(json_string)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW3aKuRBkquF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bba1d13-86dd-4943-eb7d-d29996ec1408"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMiLu_rihKIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# json_string"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TRSV-WmLm2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b05737d9-2be9-47fd-c1b2-caacc8bc74e9"
      },
      "source": [
        "def encode_texts(str_list, tokenizer=tokenizer, max_length = max_length):\n",
        "  # print(str_list)\n",
        "  str_list = [\"<start> \" + s + \" <end>\" for s in str_list]\n",
        "  seq = tokenizer.texts_to_sequences(str_list)\n",
        "  pad_seq = pad_sequences(seq, max_length, padding  ='post', truncating='post')\n",
        "  return pad_seq\n",
        "\n",
        "def decode_seq(seq_list, tokenizer = tokenizer):\n",
        "  ret = tokenizer.sequences_to_texts(seq_list)\n",
        "  ret = [s.split(\"<start>\")[1].split(\"<end>\")[0][1:-1] for s in ret]\n",
        "  return np.array(ret)\n",
        "\n",
        "print(encode_texts(['hello there', 'bye']))\n",
        "\n",
        "print(decode_seq(encode_texts(['hello there', 'bye'])))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   2  341   61    3    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   2 1017    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "['hello there' 'bye']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73BXSnRkPJ-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,  X_test, y_train,  y_test = train_test_split(padded_stimulus_sequences[10000:30000], padded_response_sequences[10000:30000], test_size = 0.1)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6lcOE8KspkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7e0c5339-bd02-4291-adcc-6385ef886ca8"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8999, 25)\n",
            "(8999, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXOeT5cAqPfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a tf dataset\n",
        "BUFFER_SIZE = len(X_train)\n",
        "BATCH_SIZE = 100\n",
        "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 100\n",
        "units = 1000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1nkhvrHrWCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOEBvxsanpb2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFTl8hi3rlbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a75f14e7-c521-445f-efbc-3ea774062d56"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([100, 25]), TensorShape([100, 25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PsRlDsesuu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "56f93d78-b8eb-4927-e70a-74fc96e64198"
      },
      "source": [
        "# Getting the trained GloVe embeddings\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n",
        "    -O /tmp/glove.6B.100d.txt\n",
        "embeddings_index = {};\n",
        "with open('/tmp/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split();\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;\n",
        "\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-25 11:03:55--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.23.128, 2404:6800:4008:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.23.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘/tmp/glove.6B.100d.txt’\n",
            "\n",
            "\r/tmp/glove.6B.100d.   0%[                    ]       0  --.-KB/s               \r/tmp/glove.6B.100d.   2%[                    ]   9.80M  49.0MB/s               \r/tmp/glove.6B.100d.   6%[>                   ]  21.16M  52.9MB/s               \r/tmp/glove.6B.100d.  10%[=>                  ]  34.45M  57.4MB/s               \r/tmp/glove.6B.100d.  17%[==>                 ]  57.70M  72.1MB/s               \r/tmp/glove.6B.100d.  24%[===>                ]  79.66M  76.3MB/s               \r/tmp/glove.6B.100d.  28%[====>               ]  93.87M  75.5MB/s               \r/tmp/glove.6B.100d.  36%[======>             ] 121.09M  83.9MB/s               \r/tmp/glove.6B.100d.  42%[=======>            ] 139.45M  84.8MB/s               \r/tmp/glove.6B.100d.  48%[========>           ] 161.23M  87.4MB/s               \r/tmp/glove.6B.100d.  56%[==========>         ] 188.66M  92.3MB/s               \r/tmp/glove.6B.100d.  58%[==========>         ] 192.01M  84.9MB/s               \r/tmp/glove.6B.100d.  62%[===========>        ] 206.61M  84.0MB/s               \r/tmp/glove.6B.100d.  68%[============>       ] 225.50M  84.7MB/s               \r/tmp/glove.6B.100d.  72%[=============>      ] 240.12M  83.9MB/s               \r/tmp/glove.6B.100d.  79%[==============>     ] 263.30M  86.0MB/s    eta 1s     \r/tmp/glove.6B.100d.  88%[================>   ] 292.40M  89.7MB/s    eta 1s     \r/tmp/glove.6B.100d.  97%[==================> ] 321.34M  94.9MB/s    eta 1s     \r/tmp/glove.6B.100d. 100%[===================>] 331.04M  96.8MB/s    in 3.6s    \n",
            "\n",
            "2020-06-25 11:03:59 (92.9 MB/s) - ‘/tmp/glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UytXUub9u40j",
        "colab_type": "text"
      },
      "source": [
        "# LDA Inclusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNa1rMAEvJ8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "abb68de4-484e-4804-82fc-68549e8cb6c6"
      },
      "source": [
        "# Loading the pre-trained model files\n",
        "!mkdir model\n",
        "!mv *.model* model/"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n",
            "mv: cannot stat '*.model*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_9QGTHguzR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cc11d3e7-f96f-49af-96d9-13e9a8b45fba"
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "fname = 'model/LDA.model'\n",
        "ConvLda = LdaModel.load(fname, mmap='r')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R96Ve6tV0UDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the topic prediction layer\n",
        "\n",
        "class TopicPrediction(tf.keras.layers.Layer): \n",
        "  \"\"\"\n",
        "    Topic Prediction using a pre-trained gensim LdaModel\n",
        "    init\n",
        "      params : \n",
        "        LdaModel : instance of trained gensim.ldamodel.LdaModel\n",
        "        num_topics : num_topics for the model\n",
        "        dims : required dims for topic vector\n",
        "    call() \n",
        "      params:\n",
        "        inp : input batch of shape (batch_size, maxlen)\n",
        "      returns :\n",
        "          predicted topic tensor of shape (batch_size, dims)\n",
        "  \"\"\"\n",
        "  def __init__(self, ldaModel, num_topics, dims):\n",
        "    super(TopicPrediction, self).__init__(trainable= False, dynamic = True)\n",
        "    self.ldaModel = ldaModel\n",
        "    assert(dims >= num_topics), f\"The required dims({dims}) are less than num_topics ({num_topics})\"\n",
        "    self.dims = dims\n",
        "    self.num_topics=num_topics\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    return\n",
        "\n",
        "  def convert_to_corpus(self, sequences):\n",
        "    corpus = []\n",
        "    for num, line in enumerate(sequences):\n",
        "      counts = [list(line).count(elt) for elt in line]\n",
        "      line_ = list(set([(line.numpy()[i], counts[i]) for i in range(len(counts))]))\n",
        "      corpus.append(line_)\n",
        "    return corpus\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\n",
        "        'lda_model' : self.ldaModel,\n",
        "        'dims' : self.dims,\n",
        "        'num_topics' : self.num_topics,\n",
        "    }\n",
        "\n",
        "  def call(self, inp):\n",
        "    # print(\"call called\")\n",
        "    bs = inp.shape[0]\n",
        "    vec = np.zeros((bs,self.dims))\n",
        "    corpus = self.convert_to_corpus(inp)\n",
        "    topic_vec = self.ldaModel.get_document_topics(corpus, minimum_probability = 0.0)\n",
        "    topic_vec = np.array(topic_vec)[:, :, 1]\n",
        "    vec[:, :self.num_topics] = topic_vec\n",
        "    return tf.convert_to_tensor(vec, dtype = tf.float32)\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ19z71Guz4R",
        "colab_type": "text"
      },
      "source": [
        "# The model, Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1ljuxcYso0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkr5ZD6Wrq1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The encoder and Decoder Models\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size, lda_model):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.encoder_units = encoder_units\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim, weights=[embeddings_matrix], trainable=False)\n",
        "    self.gru = GRU(self.encoder_units, return_sequences = True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    self.topic_pred = TopicPrediction(ldaModel=lda_model, num_topics=lda_model.num_topics, dims=1000)\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    # print(\"Call called\")\n",
        "    topic_vector = self.topic_pred.call(x)\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state, topic_vector\n",
        "  \n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_size, self.encoder_units))"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjck5wBcuGpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec123fc1-3ef8-4b43-adc4-b26625577d0d"
      },
      "source": [
        "encoder = Encoder(vocab_size+1, embedding_dim, units, BATCH_SIZE, lda_model = ConvLda)\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "print(sample_hidden.shape)\n",
        "sample_out, sample_hidden, sample_topic = encoder(example_input_batch,sample_hidden)\n",
        "print(sample_out.shape, sample_hidden.shape, sample_topic.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1000)\n",
            "(100, 25, 1000) (100, 1000) (100, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sNN5fz9ux8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "  \n",
        "  def __init__(self, units):\n",
        "    super(AttentionLayer, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1, activation='tanh')\n",
        "  \n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size) \n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    \n",
        "    # assert values.shape == (batch_size, max_len, hidden size)\n",
        "    \n",
        "    # we need to broadcast addition along the time axis to calculate the score\n",
        "    \n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    score = self.V(self.W1(query_with_time_axis)+self.W2(values))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis =1)\n",
        "\n",
        "    context_vector = attention_weights*values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis  = 1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "    "
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfq8cgTVym2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b49cd62b-3bce-40b0-e89b-c0ba096ac51b"
      },
      "source": [
        "attention_layer = AttentionLayer(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_out)\n",
        "\n",
        "print(attention_result.shape)\n",
        "print(attention_weights.shape)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1000)\n",
            "(100, 25, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWBw7fJ5y5TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The decoder model\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.vocab_size= vocab_size\n",
        "    self.decoder_units = decoder_units\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim, weights=[embeddings_matrix], trainable=False)\n",
        "    self.gru = GRU(self.decoder_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    # self.topic_pred = TopicPrediction(ldaModel = lda_model, num_topics=lda_model.num_topics, dims = 1000)\n",
        "    self.FC = Dense(self.vocab_size)\n",
        "    self.attention = AttentionLayer(self.decoder_units)\n",
        "\n",
        "  def call(self, x, hidden, encoder_output,input_topic):\n",
        "    context_vector, attention_weights = self.attention(hidden, encoder_output)\n",
        "    context_and_topic = tf.concat([context_vector, input_topic], axis = -1)\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    x = self.FC(output)\n",
        "\n",
        "    \n",
        "    return x, state, attention_weights\n",
        "  "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa06y58B1fLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86fdc9da-d60c-41b2-b5fa-123309a87f54"
      },
      "source": [
        "decoder = Decoder(vocab_size+1, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_out, sample_topic)\n",
        "\n",
        "print (f'Decoder output shape: (batch_size, vocab size) {sample_decoder_output.shape}')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (100, 13357)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf07eJEX1h1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the optimizer and loss functions\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "  mean =  tf.reduce_mean(loss)\n",
        "  return mean"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwJ818-_4KGg",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEJnd88A2wWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining checkpoint variables\n",
        "checkpoint_dir = '/content/drive/My Drive/Colab Notebooks/topic_training_checkpoints'#2/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNZy9XgV4DXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert word_index['<start>'] != word_index['start']"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIEIO1jRmBKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_loss_func(target, inp):\n",
        "  encoder_hidden = encoder.initialize_hidden_state()\n",
        "  encoder_output, encoder_hidden, encoder_topic = encoder(inp, encoder_hidden)\n",
        "  decoder_hidden = encoder_hidden\n",
        "  decoder_input = tf.expand_dims([word_index['<start>']]*inp.shape[0], 1)\n",
        "  # Teacher forcing; feeding the target as the next input\n",
        "  loss = 0\n",
        "  for t in range(1, target.shape[1]): \n",
        "    predictions, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output, encoder_topic)\n",
        "    loss += loss_function(target[:, t], predictions)\n",
        "    decoder_input = tf.expand_dims(target[:, t], 1)\n",
        "  return (loss/int(target.shape[1])).numpy()\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pEdunr7m-bX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7910188e-50eb-44ad-8b75-94dfc2b51560"
      },
      "source": [
        "batch_loss_func(example_target_batch,example_input_batch)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.8115473"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUxWFeoB27J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Pipeline\n",
        "\n",
        "# @tf.function\n",
        "def train_step(inp, target, encoder_hidden):\n",
        "  # print(\"TS Called\")\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # print(\"Got tepe\")\n",
        "    encoder_output, encoder_hidden, encoder_topic = encoder(inp, encoder_hidden)\n",
        "    # print(\"Ggot enc\")\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoder_input = tf.expand_dims([word_index['<start>']]*BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing; feeding the target as the next input\n",
        "    for t in range(1, target.shape[1]): \n",
        "      predictions, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output, encoder_topic)\n",
        "\n",
        "      loss += loss_function(target[:, t], predictions)\n",
        "\n",
        "      decoder_input = tf.expand_dims(target[:, t], 1)\n",
        "    # print(predictions.shape , \"Preds\")\n",
        "    # decoder_topic = encoder.topic_pred(predictions)\n",
        "    # target_topic = encoder.topic_pred(target)\n",
        "    # topic_loss = None\n",
        "\n",
        "  batch_loss = (loss/int(target.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "  \n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVKEyYRFuYCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a, b = next(iter(val_dataset))\n",
        "val_loss = batch_loss_func(a, b)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLeG9oBX6Di8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "941c3a8d-294f-4c32-af32-d2fc929daa34"
      },
      "source": [
        "epochs = 20\n",
        "# loss_hist = []\n",
        "# val_loss_hist = []\n",
        "print(f\"Training on {BUFFER_SIZE} samples : \")\n",
        "for epoch in range(1, epochs+1):\n",
        "  start = time.time()\n",
        "  encoder_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  disp_loss = 0\n",
        "  val_loss = 0\n",
        "  batch_loss = 0\n",
        "  eta = np.inf\n",
        "  for batch, (inp, target) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    elapsed =  time.time() - start\n",
        "    at.progress_bar(f\"Epoch {epoch:3.0f}/{epochs} \", batch, steps_per_epoch, output_vals = {'time_elapsed (in s)':elapsed, 'loss':disp_loss}, jump_line = False)\n",
        "    batch_loss = train_step(inp, target, encoder_hidden)\n",
        "    total_loss += batch_loss\n",
        "    disp_loss = total_loss/(max(1, batch))\n",
        "  val_x, val_y = next(iter(val_dataset))\n",
        "  val_loss = batch_loss_func(val_y,val_x)\n",
        "  print(f\"val_loss: {val_loss:3.4f}\")\n",
        "  val_loss_hist.append(val_loss)\n",
        "  total_loss = total_loss / steps_per_epoch\n",
        "  loss_hist.append(total_loss)\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 8999 samples : \n",
            "Epoch   1/10 :[==============================](100.00%)  time_elapsed (in s) : 826.11 loss : 2.49 val_loss: 2.3467\n",
            "Epoch   2/10 :[==============================](100.00%)  time_elapsed (in s) : 824.38 loss : 2.44 val_loss: 2.3165\n",
            "Epoch   3/10 :[==============================](100.00%)  time_elapsed (in s) : 828.68 loss : 2.40 val_loss: 2.2851\n",
            "Epoch   4/10 :[==============================](100.00%)  time_elapsed (in s) : 829.29 loss : 2.35 val_loss: 2.2505\n",
            "Epoch   5/10 :[==============================](100.00%)  time_elapsed (in s) : 828.58 loss : 2.31 val_loss: 2.2257\n",
            "Epoch   6/10 :[==============================](100.00%)  time_elapsed (in s) : 832.62 loss : 2.27 val_loss: 2.1887\n",
            "Epoch   7/10 :[==============================](100.00%)  time_elapsed (in s) : 851.33 loss : 2.22 val_loss: 2.1656\n",
            "Epoch   8/10 :[==============================](100.00%)  time_elapsed (in s) : 822.45 loss : 2.18 val_loss: 2.1541\n",
            "Epoch   9/10 :[==============================](100.00%)  time_elapsed (in s) : 826.16 loss : 2.15 val_loss: 2.1566\n",
            "Epoch  10/10 :[==============================](100.00%)  time_elapsed (in s) : 825.00 loss : 2.11 val_loss: 2.1475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP9xQBb1axwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(sample_size, epochs, loss_hist = [], val_hist = []):\n",
        "  print(f\"Training on {sample_size} samples : \")\n",
        "  for epoch in range(1, epochs+1):\n",
        "    start = time.time()\n",
        "    encoder_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    disp_loss = 0\n",
        "    val_loss = 0\n",
        "    batch_loss = 0\n",
        "    eta = np.inf\n",
        "    for batch, (inp, target) in enumerate(dataset.take(steps_per_epoch)):\n",
        "      batch_start = time.time()\n",
        "      elapsed = batch_start - start\n",
        "      at.progress_bar(f\"Epoch {epoch:3.0f}/{epochs} \", batch, steps_per_epoch, output_vals = {'eta(s)':eta, 'time_elapsed(s)':elapsed, 'loss':disp_loss}, jump_line = False)\n",
        "      batch_loss= train_step(inp, target, encoder_hidden)\n",
        "      total_loss += batch_loss\n",
        "      disp_loss = total_loss/(max(1, batch))\n",
        "      batch_elapsed = time.time()-batch_start\n",
        "      eta = (steps_per_epoch-(batch+1))*batch_elapsed\n",
        "    val_x, val_y = next(iter(val_dataset))\n",
        "    val_loss = batch_loss_func(val_y,val_x)\n",
        "    print(f\"val_loss: {val_loss:3.4f}\")\n",
        "    val_loss_hist.append(val_loss)\n",
        "    total_loss = total_loss / steps_per_epoch\n",
        "    loss_hist.append(total_loss)\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  return loss_hist, val_hist"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NhYc5tay62z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "02c9ed65-2df5-4209-b8bb-32cf1c7da5c7"
      },
      "source": [
        "loss_hist, val_loss_hist = fit_model(BUFFER_SIZE, 20, loss_hist, val_loss_hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 8999 samples : \n",
            "Epoch   1/20 :[==============================](100.00%)  eta(s) : 18.67 time_elapsed(s) : 830.36 loss : 2.09 val_loss: 2.1370\n",
            "Epoch   2/20 :[==============================](100.00%)  eta(s) : 18.95 time_elapsed(s) : 822.69 loss : 2.05 val_loss: 2.1409\n",
            "Epoch   3/20 :[==============================](100.00%)  eta(s) : 18.09 time_elapsed(s) : 830.62 loss : 2.02 val_loss: 2.1443\n",
            "Epoch   4/20 :[==============================](100.00%)  eta(s) : 19.75 time_elapsed(s) : 833.17 loss : 1.99 val_loss: 2.1558\n",
            "Epoch   5/20 :[==============================](100.00%)  eta(s) : 19.43 time_elapsed(s) : 844.68 loss : 1.95 val_loss: 2.1484\n",
            "Epoch   6/20 :[==============================](100.00%)  eta(s) : 19.11 time_elapsed(s) : 833.23 loss : 1.91 val_loss: 2.1559\n",
            "Epoch   7/20 :[==============================](100.00%)  eta(s) : 20.12 time_elapsed(s) : 827.76 loss : 1.88 val_loss: 2.1661\n",
            "Epoch   8/20 :[==============================](100.00%)  eta(s) : 19.23 time_elapsed(s) : 830.99 loss : 1.84 val_loss: 2.1804\n",
            "Epoch   9/20 :[==============================](100.00%)  eta(s) : 18.42 time_elapsed(s) : 839.46 loss : 1.79 val_loss: 2.1924\n",
            "Epoch  10/20 :[==============================](100.00%)  eta(s) : 19.02 time_elapsed(s) : 835.33 loss : 1.75 val_loss: 2.2030\n",
            "Epoch  11/20 :[==============================](100.00%)  eta(s) : 18.45 time_elapsed(s) : 823.68 loss : 1.71 val_loss: 2.2168\n",
            "Epoch  12/20 :[==============================](100.00%)  eta(s) : 19.33 time_elapsed(s) : 829.60 loss : 1.66 val_loss: 2.2330\n",
            "Epoch  13/20 :[==============================](100.00%)  eta(s) : 18.87 time_elapsed(s) : 823.36 loss : 1.61 val_loss: 2.2509\n",
            "Epoch  14/20 :[==============================](100.00%)  eta(s) : 19.20 time_elapsed(s) : 829.06 loss : 1.56 val_loss: 2.2739\n",
            "Epoch  15/20 :[==============================](100.00%)  eta(s) : 18.51 time_elapsed(s) : 826.72 loss : 1.51 val_loss: 2.3009\n",
            "Epoch  16/20 :[==============================](100.00%)  eta(s) : 18.07 time_elapsed(s) : 828.70 loss : 1.46 val_loss: 2.3110\n",
            "Epoch  17/20 :[==============================](100.00%)  eta(s) : 19.13 time_elapsed(s) : 828.13 loss : 1.40 val_loss: 2.3391\n",
            "Epoch  18/20 :[==================~~~~~~~~~~~~](59.32%)  eta(s) : 510.23 time_elapsed(s) : 328.36 loss : 1.35 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qruJq4DiB4ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(loss_hist, label = 'loss')\n",
        "plt.plot(val_loss_hist, label = 'val_loss')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3dj2dVwElNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32c6aa2d-95f2-42d4-cb64-a28016b44202"
      },
      "source": [
        "rm -r \"/content/drive/My Drive/Colab Notebooks/topic_training_checkpoints\"\n",
        "echo \"removed all checkpoints\""
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'checkpoint_dir': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "763n7AFcTMFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "323ae660-70be-4d83-fd6d-65fb2e15da92"
      },
      "source": [
        "print(\"Saving checkpoint at\", checkpoint.save(file_prefix = checkpoint_prefix))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving checkpoint at /content/drive/My Drive/Colab Notebooks/topic_training_checkpoints/ckpt-3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBefuv30-MM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length, max_length))\n",
        "\n",
        "  inputs = encode_texts([sentence])\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "\n",
        "  encoder_output, encoder_hidden, encoder_topic = encoder(inputs, hidden)\n",
        "\n",
        "  decoder_hidden = encoder_hidden\n",
        "  decoder_input = tf.expand_dims([word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length):\n",
        "    predictions, decoder_hidden, attention_weights = decoder(decoder_input, decoder_hidden, encoder_output, encoder_topic)\n",
        "\n",
        "    # Storing the attention weights to plot later\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "    # print(predictions.shape)\n",
        "    # input()\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += index_word[predicted_id]+' '\n",
        "\n",
        "    if index_word[predicted_id]=='<end>':\n",
        "      return result, sentence, attention_plot\n",
        "    \n",
        "    decoder_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot\n",
        "\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tznO-IWpB2nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting attention weights\n",
        "import matplotlib.ticker as ticker\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxeuR8fECIPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_response(sentence, plot_graph = False):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted Response: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  if plot_graph :plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D75uLkpwk75S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44a87a81-e565-44c1-f250-eede1003e198"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctRHtNU-lBPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd4f7df5-a9fb-45f5-e041-4330e435fefe"
      },
      "source": [
        "checkpoint_dir"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/topic_training_checkpoints'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2BdLY05Dy33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30b8a459-09bc-4ce7-b053-fddbe742e8c7"
      },
      "source": [
        "# Restore from last checkpoint \n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa83e6ed630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTqjFrvNCj6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def argmax_beam(tensor, width):\n",
        "  arr = tensor.numpy()\n",
        "  assert arr.shape[0] == 1\n",
        "  arr_ = [c for c in arr[0]]\n",
        "  assert len(arr_) >= width, \"Beam width is greater than the tensor length\"\n",
        "  args = []\n",
        "  for i in range(width):\n",
        "    argm = np.argmax(arr_)\n",
        "    args.append(argm)\n",
        "    arr_[argm] = -np.inf\n",
        "  # print(args)\n",
        "  # input()\n",
        "  return args"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blF5rXTOEBFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "32c1a47c-4db3-4365-fadb-86ddd53ed54c"
      },
      "source": [
        "a = np.random.randn(1, 5)\n",
        "print(a)\n",
        "a = tf.convert_to_tensor(a)\n",
        "b = np.random.randn(1, 5)\n",
        "print(b)\n",
        "b = tf.convert_to_tensor(b)\n",
        "# print([*argmax_beam(a, 3), *argmax_beam(b, 3)])\n",
        "c = tf.convert_to_tensor([[1, 2, 3]])\n",
        "print(argmax_beam(c, 2))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.55639375  0.34663659  1.03948518 -0.3964471   1.77503784]]\n",
            "[[-0.69636639 -0.20981176 -0.19952054  0.06869421 -0.13426373]]\n",
            "[2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3-kltX7Z9ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def beam_search_evaluate(sentence, beam_width=3, length_norm_alpha = 0.5):\n",
        "  inputs = encode_texts([sentence])\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  result = ['']*beam_width\n",
        "  results = []\n",
        "  scores_list = []\n",
        "  scores = [0]*beam_width\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  encoder_output, encoder_hidden, encoder_topic = encoder(inputs, hidden)\n",
        "  decoder_hidden = encoder_hidden\n",
        "  decoder_input = tf.expand_dims([word_index['<start>']], 0)\n",
        "  \n",
        "  # At t = 0\n",
        "  prediction, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output, encoder_topic)\n",
        "  ids = argmax_beam(prediction, beam_width)\n",
        "  predicted_id = []\n",
        "  for i, id in enumerate(ids):\n",
        "    result[i]+= index_word[id] + \" \"\n",
        "    predicted_id.append(id)\n",
        "  decoder_input = []\n",
        "  for i in range(beam_width) : \n",
        "      decoder_input.append(tf.expand_dims([predicted_id[i]], 0))\n",
        "  decoder_hidden = [decoder_hidden]*beam_width\n",
        "\n",
        "  # After t=0  \n",
        "  for t in range(1, max_length):\n",
        "    predictions = []\n",
        "    \n",
        "    for i in range(beam_width):\n",
        "      pred, decoder_hidden[i], _ = decoder(decoder_input[i], decoder_hidden[i], encoder_output, encoder_topic)\n",
        "      predictions.append(pred)\n",
        "    ids = [] # List of tuples : (id, predicted probability, decoder_hidden from beam)\n",
        "    \n",
        "    for beam in range(beam_width):\n",
        "      predicted_ids = argmax_beam(predictions[beam], beam_width)\n",
        "      for id in predicted_ids:\n",
        "        ids.append((id, predictions[beam][0,id],decoder_hidden[beam], result[beam])) \n",
        "    \n",
        "    probs = tf.convert_to_tensor([[i[1] for i in ids]])\n",
        "    best_id_indices = argmax_beam(probs, beam_width)\n",
        "    predicted_id = []\n",
        "\n",
        "    for i, idx in enumerate(best_id_indices):\n",
        "      pr_id, score, decoder_hidden[i], result[i] = ids[idx]\n",
        "      result[i] += index_word[pr_id] + \" \"\n",
        "      predicted_id.append(pr_id)\n",
        "      scores[i] = np.log(score.numpy())\n",
        "      \n",
        "\n",
        "    for i in range(beam_width):\n",
        "      if index_word[predicted_id[i]]=='<end>':        \n",
        "        results.append(result[i]) \n",
        "        # scores_list.append(scores[i])#*np.log(t))\n",
        "        \n",
        "    \n",
        "    if len(results) == beam_width:\n",
        "      return results, scores\n",
        "    \n",
        "    for i in range(beam_width) : \n",
        "      decoder_input[i] = tf.expand_dims([predicted_id[i]], 0)\n",
        "\n",
        "  return result, scores"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8okBPqPYcC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_response_beam(sentence, beam_width=3):\n",
        "  responses, scores = beam_search_evaluate(sentence, beam_width)\n",
        "  print(f\"Input : {sentence}\")\n",
        "  print(\"Responses\")\n",
        "  for r, s in zip(responses, scores):\n",
        "    print(r.split(\" <end>\")[0], \": Score = \", s)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5BkkKXt7Kby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "171b36ca-19b2-4a3d-e361-9f2afbada6ca"
      },
      "source": [
        "get_response_beam(\"what happened?\")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : what happened?\n",
            "Responses\n",
            "i think : Score =  1.717265\n",
            "i think i think : Score =  1.6526518\n",
            "i think i think i think : Score =  1.5449833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1txBoZH7Qun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2d35f069-d635-4c5b-b1dd-947d94b9f43b"
      },
      "source": [
        "get_response(\"what happened?\")"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: what happened?\n",
            "Predicted Response: i don't <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnS986Mp-ll-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "df18bfd2-3e6f-48f5-81aa-e39a3695d1a5"
      },
      "source": [
        "get_response_beam(\"i got banned from the club's page\")"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : i got banned from the club's page\n",
            "Responses\n",
            "i think : Score =  1.7124393\n",
            "i think i think : Score =  1.6652694\n",
            "i think i think i think : Score =  1.5894401\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}