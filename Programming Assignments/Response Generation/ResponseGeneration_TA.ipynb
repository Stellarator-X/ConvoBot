{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResponseGeneration_tf_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "P6HGYBDPu9GK",
        "JZ19z71Guz4R"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6HGYBDPu9GK",
        "colab_type": "text"
      },
      "source": [
        "# Datagen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppc9JeXJFj1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c8a546a-6290-46f3-e5e9-b7c8e8606080"
      },
      "source": [
        "!pip install aesthetix"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aesthetix in /usr/local/lib/python3.6/dist-packages (0.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mu_225xS3Aj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2fe111a-4a7e-4978-968d-35ece0f05b97"
      },
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-IzvHNAVhEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "acae314c-4a25-40ad-aef8-9d06dbd5f8c8"
      },
      "source": [
        "import os\n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "import aesthetix as at\n",
        "\n",
        "# Downloading movie_lines\n",
        "if \"movie_lines.txt\" not in os.popen(\"ls\").read():\n",
        "  !wget https://raw.githubusercontent.com/Stellarator-X/ConvoBot/servus/Programming%20Assignments/Response%20Generation/movie_lines.txt\n",
        "\n",
        "movielines = open(\"movie_lines.txt\", mode='r')\n",
        "print(movielines)\n",
        "lines = movielines.readlines()\n",
        "print(len(lines))\n",
        "\n",
        "def clean_str(_str):\n",
        "  _str = _str.strip()\n",
        "  _str = _str.lower()\n",
        "  _str = _str.replace(\".\", \"\")\n",
        "  _str = _str.replace(\",\", \"\")\n",
        "  _str = _str.replace(\"?\", \"\")\n",
        "  _str = _str.replace(\"!\", \"\")\n",
        "  _str = _str.replace(\":\", \"\")\n",
        "  _str = _str.replace(\">\", \"\")\n",
        "  _str = _str.replace(\"<\", \"\")\n",
        "  _str = _str.replace(\"-\", \" \")\n",
        "  _str = _str.replace(\"_\", \" \")\n",
        "  _str = _str.replace(\"\\\\\", \"\")\n",
        "  _str = _str.replace(\"  \", \" \")\n",
        "  return _str\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_io.TextIOWrapper name='movie_lines.txt' mode='r' encoding='UTF-8'>\n",
            "304713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUKBdeJXLBP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "6790ecfc-0601-4d91-f609-c040cfc154d4"
      },
      "source": [
        "sample_size = 20000\n",
        "cleanlines = []\n",
        "for i, line in enumerate(lines[:sample_size]):\n",
        "  at.progress_bar(\"Cleaning the lines\", i, len(lines[:sample_size]))\n",
        "  speaker, line = line.split('+++$+++ ')[-2:]\n",
        "  cleanlines.append([speaker.split(\" \")[0], line.split('\\n')[0]])\n",
        "\n",
        "cleanlines.reverse()\n",
        "cleanlines = np.array(cleanlines)\n",
        "for line in cleanlines[:10]:\n",
        "  print(line[0],\":\",line[1])\n",
        "\n",
        "\n",
        "# Forming the dataset \n",
        "response_data = []\n",
        "l = len(cleanlines)-1\n",
        "for i, line in enumerate(cleanlines[:-1]):\n",
        "  at.progress_bar(\"Generating Stimulus-Response Pairs\", i, l)\n",
        "  speaker, utterance = line\n",
        "  next_speaker, next_utterance = cleanlines[i+1]\n",
        "  if speaker is not next_speaker:\n",
        "    response_data.append(np.array([\"<start> \"+clean_str(utterance)+\" <end>\", \"<start> \"+clean_str(next_utterance)+\" <end>\"]))\n",
        "  \n",
        "response_data = np.array(response_data)\n",
        "print(response_data.shape)\n",
        "print(response_data[-10:])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning the lines:[==============================](100.00%)  \n",
            "PRINCESS : Sir, I... come to beg you to confess all, and swear allegiance to the king, that he might show you mercy.\n",
            "WALLACE : Will he show mercy to my country? Will he take back his soldiers, and let us rule ourselves?\n",
            "PRINCESS : Mercy... is to die quickly. Perhaps even live in the Tower. In time, who knows what can happen, if you can only live.\n",
            "WALLACE : If I swear to him, then everything I am is dead already.\n",
            "PRINCESS : You will die! It will be awful!\n",
            "WALLACE : Every man dies. Not every man really lives.\n",
            "PRINCESS : Drink this! It will dull your pain.\n",
            "WALLACE : It will numb my wits, and I must have them all. If I'm senseless, or if I wail, then Longshanks will have broken me.\n",
            "PRINCESS : I can't bear the thought of your torture. Take it!\n",
            "NICOLETTE : When the king returns he will bury them in those new clothes. Scotland is in chaos. Your husband is secretly sending an army north.\n",
            "Generating Stimulus-Response Pairs:[==============================](100.00%)  \n",
            "(19999, 2)\n",
            "[['<start> the \"real you\" <end>'\n",
            "  '<start> like my fear of wearing pastels <end>']\n",
            " ['<start> like my fear of wearing pastels <end>'\n",
            "  '<start> i\\'m kidding you know how sometimes you just become this \"persona\" and you don\\'t know how to quit <end>']\n",
            " ['<start> i\\'m kidding you know how sometimes you just become this \"persona\" and you don\\'t know how to quit <end>'\n",
            "  '<start> no <end>']\n",
            " ['<start> no <end>'\n",
            "  \"<start> okay  you're gonna need to learn how to lie <end>\"]\n",
            " [\"<start> okay  you're gonna need to learn how to lie <end>\"\n",
            "  '<start> wow <end>']\n",
            " ['<start> wow <end>' \"<start> let's go <end>\"]\n",
            " [\"<start> let's go <end>\" '<start> she okay <end>']\n",
            " ['<start> she okay <end>' '<start> i hope so <end>']\n",
            " ['<start> i hope so <end>' '<start> they do to <end>']\n",
            " ['<start> they do to <end>' '<start> they do not <end>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZQK9q-1LL2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "6a9519df-a836-4355-8788-56f7dd73a555"
      },
      "source": [
        "a = [len(s) for s in response_data[:,0]]\n",
        "plt.plot(a)\n",
        "plt.xlabel(\"Utterances\")\n",
        "plt.ylabel(\"Length\")\n",
        "plt.show()\n",
        "print(np.mean(np.array(a)))\n",
        "print(\"Longest utterance : \", response_data[np.argmax(a), 0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "64.50467523376169\n",
            "Longest utterance :  <start> you've got penthouse playboy hustler etc nobody even considers them pornography anymore then there's mainstream hardcore triple x the difference is penetration that's hardcore that whole industry's up in the valley writers directors porn stars they're celebrities or they think they are they pump out 150 videos a week a week they've even got a porno academy awards america loves pornography anybody tells you they never use pornography they're lying somebody's buying those videos somebody's out there spending 900 million dollars a year on phone sex know what else it's only gonna get worse more and more you'll see perverse hardcore coming into the mainstream because that's evolution desensitization oh my god elvis presley's wiggling his hips how offensive nowadays mtv's showing girls dancing around in thong bikinis with their asses hanging out know what i mean for the porn addict big tits aren't big enough after a while they have to be the biggest tits ever some porn chicks are putting in breast implants bigger than your head literally soon playboy is gonna be penthouse penthouse'll be hustler hustler'll be hardcore and hardcore films'll be medical films people'll be jerking off to women laying around with open wounds there's nowhere else for it to go <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZW-mSq2ZKfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing the Data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "oov_token = \"<OOV>\"\n",
        "max_length = 25\n",
        "stimuli = response_data[:, 0]\n",
        "responses = response_data[:, 1]\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_token, filters = \"\")\n",
        "tokenizer.fit_on_texts(stimuli)\n",
        "# with open(\"Tokens.txt\") as file:\n",
        "#   json_string = file.read()\n",
        "# tokenizer = tokenizer_from_json(json_string)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "index_word = {word_index[word]:word for word in word_index}\n",
        "vocab_size = len(word_index)\n",
        "stimulus_sequences = tokenizer.texts_to_sequences(stimuli)\n",
        "response_sequences = tokenizer.texts_to_sequences(responses)\n",
        "\n",
        "padded_stimulus_sequences = pad_sequences(stimulus_sequences, maxlen = max_length ,padding = 'post', truncating = 'post')\n",
        "padded_response_sequences = pad_sequences(response_sequences, maxlen = max_length, padding = 'post', truncating = 'post')\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX2Wnd7Re4Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_string = tokenizer.to_json()\n",
        "with open(\"Tokens.txt\", \"w\") as file:\n",
        "  file.write(json_string)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW3aKuRBkquF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bba1d13-86dd-4943-eb7d-d29996ec1408"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMiLu_rihKIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# json_string"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TRSV-WmLm2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b05737d9-2be9-47fd-c1b2-caacc8bc74e9"
      },
      "source": [
        "def encode_texts(str_list, tokenizer=tokenizer, max_length = max_length):\n",
        "  # print(str_list)\n",
        "  str_list = [\"<start> \" + s + \" <end>\" for s in str_list]\n",
        "  seq = tokenizer.texts_to_sequences(str_list)\n",
        "  pad_seq = pad_sequences(seq, max_length, padding  ='post', truncating='post')\n",
        "  return pad_seq\n",
        "\n",
        "def decode_seq(seq_list, tokenizer = tokenizer):\n",
        "  ret = tokenizer.sequences_to_texts(seq_list)\n",
        "  ret = [s.split(\"<start>\")[1].split(\"<end>\")[0][1:-1] for s in ret]\n",
        "  return np.array(ret)\n",
        "\n",
        "print(encode_texts(['hello there', 'bye']))\n",
        "\n",
        "print(decode_seq(encode_texts(['hello there', 'bye'])))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   2  341   61    3    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   2 1017    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "['hello there' 'bye']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73BXSnRkPJ-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,  X_test, y_train,  y_test = train_test_split(padded_stimulus_sequences[10000:30000], padded_response_sequences[10000:30000], test_size = 0.1)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6lcOE8KspkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7e0c5339-bd02-4291-adcc-6385ef886ca8"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8999, 25)\n",
            "(8999, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXOeT5cAqPfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a tf dataset\n",
        "BUFFER_SIZE = len(X_train)\n",
        "BATCH_SIZE = 100\n",
        "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 100\n",
        "units = 1000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1nkhvrHrWCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOEBvxsanpb2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFTl8hi3rlbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a75f14e7-c521-445f-efbc-3ea774062d56"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([100, 25]), TensorShape([100, 25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PsRlDsesuu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "56f93d78-b8eb-4927-e70a-74fc96e64198"
      },
      "source": [
        "# Getting the trained GloVe embeddings\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n",
        "    -O /tmp/glove.6B.100d.txt\n",
        "embeddings_index = {};\n",
        "with open('/tmp/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split();\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;\n",
        "\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-25 11:03:55--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.23.128, 2404:6800:4008:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.23.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘/tmp/glove.6B.100d.txt’\n",
            "\n",
            "\r/tmp/glove.6B.100d.   0%[                    ]       0  --.-KB/s               \r/tmp/glove.6B.100d.   2%[                    ]   9.80M  49.0MB/s               \r/tmp/glove.6B.100d.   6%[>                   ]  21.16M  52.9MB/s               \r/tmp/glove.6B.100d.  10%[=>                  ]  34.45M  57.4MB/s               \r/tmp/glove.6B.100d.  17%[==>                 ]  57.70M  72.1MB/s               \r/tmp/glove.6B.100d.  24%[===>                ]  79.66M  76.3MB/s               \r/tmp/glove.6B.100d.  28%[====>               ]  93.87M  75.5MB/s               \r/tmp/glove.6B.100d.  36%[======>             ] 121.09M  83.9MB/s               \r/tmp/glove.6B.100d.  42%[=======>            ] 139.45M  84.8MB/s               \r/tmp/glove.6B.100d.  48%[========>           ] 161.23M  87.4MB/s               \r/tmp/glove.6B.100d.  56%[==========>         ] 188.66M  92.3MB/s               \r/tmp/glove.6B.100d.  58%[==========>         ] 192.01M  84.9MB/s               \r/tmp/glove.6B.100d.  62%[===========>        ] 206.61M  84.0MB/s               \r/tmp/glove.6B.100d.  68%[============>       ] 225.50M  84.7MB/s               \r/tmp/glove.6B.100d.  72%[=============>      ] 240.12M  83.9MB/s               \r/tmp/glove.6B.100d.  79%[==============>     ] 263.30M  86.0MB/s    eta 1s     \r/tmp/glove.6B.100d.  88%[================>   ] 292.40M  89.7MB/s    eta 1s     \r/tmp/glove.6B.100d.  97%[==================> ] 321.34M  94.9MB/s    eta 1s     \r/tmp/glove.6B.100d. 100%[===================>] 331.04M  96.8MB/s    in 3.6s    \n",
            "\n",
            "2020-06-25 11:03:59 (92.9 MB/s) - ‘/tmp/glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UytXUub9u40j",
        "colab_type": "text"
      },
      "source": [
        "# LDA Inclusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNa1rMAEvJ8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "abb68de4-484e-4804-82fc-68549e8cb6c6"
      },
      "source": [
        "# Loading the pre-trained model files\n",
        "!mkdir model\n",
        "!mv *.model* model/"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n",
            "mv: cannot stat '*.model*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_9QGTHguzR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cc11d3e7-f96f-49af-96d9-13e9a8b45fba"
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "fname = 'model/LDA.model'\n",
        "ConvLda = LdaModel.load(fname, mmap='r')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R96Ve6tV0UDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the topic prediction layer\n",
        "\n",
        "class TopicPrediction(tf.keras.layers.Layer): \n",
        "  \"\"\"\n",
        "    Topic Prediction using a pre-trained gensim LdaModel\n",
        "    init\n",
        "      params : \n",
        "        LdaModel : instance of trained gensim.ldamodel.LdaModel\n",
        "        num_topics : num_topics for the model\n",
        "        dims : required dims for topic vector\n",
        "    call() \n",
        "      params:\n",
        "        inp : input batch of shape (batch_size, maxlen)\n",
        "      returns :\n",
        "          predicted topic tensor of shape (batch_size, dims)\n",
        "  \"\"\"\n",
        "  def __init__(self, ldaModel, num_topics, dims):\n",
        "    super(TopicPrediction, self).__init__(trainable= False, dynamic = True)\n",
        "    self.ldaModel = ldaModel\n",
        "    assert(dims >= num_topics), f\"The required dims({dims}) are less than num_topics ({num_topics})\"\n",
        "    self.dims = dims\n",
        "    self.num_topics=num_topics\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    return\n",
        "\n",
        "  def convert_to_corpus(self, sequences):\n",
        "    corpus = []\n",
        "    for num, line in enumerate(sequences):\n",
        "      counts = [list(line).count(elt) for elt in line]\n",
        "      line_ = list(set([(line.numpy()[i], counts[i]) for i in range(len(counts))]))\n",
        "      corpus.append(line_)\n",
        "    return corpus\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\n",
        "        'lda_model' : self.ldaModel,\n",
        "        'dims' : self.dims,\n",
        "        'num_topics' : self.num_topics,\n",
        "    }\n",
        "\n",
        "  def call(self, inp):\n",
        "    # print(\"call called\")\n",
        "    bs = inp.shape[0]\n",
        "    vec = np.zeros((bs,self.dims))\n",
        "    corpus = self.convert_to_corpus(inp)\n",
        "    topic_vec = self.ldaModel.get_document_topics(corpus, minimum_probability = 0.0)\n",
        "    topic_vec = np.array(topic_vec)[:, :, 1]\n",
        "    vec[:, :self.num_topics] = topic_vec\n",
        "    return tf.convert_to_tensor(vec, dtype = tf.float32)\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ19z71Guz4R",
        "colab_type": "text"
      },
      "source": [
        "# The model, Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1ljuxcYso0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkr5ZD6Wrq1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The encoder and Decoder Models\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size, lda_model):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.encoder_units = encoder_units\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim, weights=[embeddings_matrix], trainable=False)\n",
        "    self.gru = GRU(self.encoder_units, return_sequences = True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    self.topic_pred = TopicPrediction(ldaModel=lda_model, num_topics=lda_model.num_topics, dims=1000)\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    # print(\"Call called\")\n",
        "    topic_vector = self.topic_pred.call(x)\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state, topic_vector\n",
        "  \n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_size, self.encoder_units))"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjck5wBcuGpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec123fc1-3ef8-4b43-adc4-b26625577d0d"
      },
      "source": [
        "encoder = Encoder(vocab_size+1, embedding_dim, units, BATCH_SIZE, lda_model = ConvLda)\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "print(sample_hidden.shape)\n",
        "sample_out, sample_hidden, sample_topic = encoder(example_input_batch,sample_hidden)\n",
        "print(sample_out.shape, sample_hidden.shape, sample_topic.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1000)\n",
            "(100, 25, 1000) (100, 1000) (100, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sNN5fz9ux8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "  \n",
        "  def __init__(self, units):\n",
        "    super(AttentionLayer, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1, activation='tanh')\n",
        "  \n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size) \n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    \n",
        "    # assert values.shape == (batch_size, max_len, hidden size)\n",
        "    \n",
        "    # we need to broadcast addition along the time axis to calculate the score\n",
        "    \n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    score = self.V(self.W1(query_with_time_axis)+self.W2(values))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis =1)\n",
        "\n",
        "    context_vector = attention_weights*values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis  = 1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "    "
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfq8cgTVym2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b49cd62b-3bce-40b0-e89b-c0ba096ac51b"
      },
      "source": [
        "attention_layer = AttentionLayer(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_out)\n",
        "\n",
        "print(attention_result.shape)\n",
        "print(attention_weights.shape)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1000)\n",
            "(100, 25, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWBw7fJ5y5TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The decoder model\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.vocab_size= vocab_size\n",
        "    self.decoder_units = decoder_units\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim, weights=[embeddings_matrix], trainable=False)\n",
        "    self.gru = GRU(self.decoder_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    # self.topic_pred = TopicPrediction(ldaModel = lda_model, num_topics=lda_model.num_topics, dims = 1000)\n",
        "    self.FC = Dense(self.vocab_size)\n",
        "    self.attention = AttentionLayer(self.decoder_units)\n",
        "\n",
        "  def call(self, x, hidden, encoder_output,input_topic):\n",
        "    context_vector, attention_weights = self.attention(hidden, encoder_output)\n",
        "    context_and_topic = tf.concat([context_vector, input_topic], axis = -1)\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    x = self.FC(output)\n",
        "\n",
        "    \n",
        "    return x, state, attention_weights\n",
        "  "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa06y58B1fLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86fdc9da-d60c-41b2-b5fa-123309a87f54"
      },
      "source": [
        "decoder = Decoder(vocab_size+1, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_out, sample_topic)\n",
        "\n",
        "print (f'Decoder output shape: (batch_size, vocab size) {sample_decoder_output.shape}')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (100, 13357)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf07eJEX1h1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the optimizer and loss functions\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "  mean =  tf.reduce_mean(loss)\n",
        "  return mean"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwJ818-_4KGg",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEJnd88A2wWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining checkpoint variables\n",
        "checkpoint_dir = '/content/drive/My Drive/Colab Notebooks/topic_training_checkpoints'#2/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNZy9XgV4DXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert word_index['<start>'] != word_index['start']"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIEIO1jRmBKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_loss_func(target, inp):\n",
        "  encoder_hidden = encoder.initialize_hidden_state()\n",
        "  encoder_output, encoder_hidden, encoder_topic = encoder(inp, encoder_hidden)\n",
        "  decoder_hidden = encoder_hidden\n",
        "  decoder_input = tf.expand_dims([word_index['<start>']]*inp.shape[0], 1)\n",
        "  # Teacher forcing; feeding the target as the next input\n",
        "  loss = 0\n",
        "  for t in range(1, target.shape[1]): \n",
        "    predictions, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output, encoder_topic)\n",
        "    loss += loss_function(target[:, t], predictions)\n",
        "    decoder_input = tf.expand_dims(target[:, t], 1)\n",
        "  return (loss/int(target.shape[1])).numpy()\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pEdunr7m-bX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7910188e-50eb-44ad-8b75-94dfc2b51560"
      },
      "source": [
        "batch_loss_func(example_target_batch,example_input_batch)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.8115473"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUxWFeoB27J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Pipeline\n",
        "\n",
        "# @tf.function\n",
        "def train_step(inp, target, encoder_hidden):\n",
        "  # print(\"TS Called\")\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # print(\"Got tepe\")\n",
        "    encoder_output, encoder_hidden, encoder_topic = encoder(inp, encoder_hidden)\n",
        "    # print(\"Ggot enc\")\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoder_input = tf.expand_dims([word_index['<start>']]*BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing; feeding the target as the next input\n",
        "    for t in range(1, target.shape[1]): \n",
        "      predictions, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output, encoder_topic)\n",
        "\n",
        "      loss += loss_function(target[:, t], predictions)\n",
        "\n",
        "      decoder_input = tf.expand_dims(target[:, t], 1)\n",
        "    # print(predictions.shape , \"Preds\")\n",
        "    # decoder_topic = encoder.topic_pred(predictions)\n",
        "    # target_topic = encoder.topic_pred(target)\n",
        "    # topic_loss = None\n",
        "\n",
        "  batch_loss = (loss/int(target.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "  \n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVKEyYRFuYCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a, b = next(iter(val_dataset))\n",
        "val_loss = batch_loss_func(a, b)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLeG9oBX6Di8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "941c3a8d-294f-4c32-af32-d2fc929daa34"
      },
      "source": [
        "epochs = 20\n",
        "# loss_hist = []\n",
        "# val_loss_hist = []\n",
        "print(f\"Training on {BUFFER_SIZE} samples : \")\n",
        "for epoch in range(1, epochs+1):\n",
        "  start = time.time()\n",
        "  encoder_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  disp_loss = 0\n",
        "  val_loss = 0\n",
        "  batch_loss = 0\n",
        "  eta = np.inf\n",
        "  for batch, (inp, target) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    elapsed =  time.time() - start\n",
        "    at.progress_bar(f\"Epoch {epoch:3.0f}/{epochs} \", batch, steps_per_epoch, output_vals = {'time_elapsed (in s)':elapsed, 'loss':disp_loss}, jump_line = False)\n",
        "    batch_loss = train_step(inp, target, encoder_hidden)\n",
        "    total_loss += batch_loss\n",
        "    disp_loss = total_loss/(max(1, batch))\n",
        "  val_x, val_y = next(iter(val_dataset))\n",
        "  val_loss = batch_loss_func(val_y,val_x)\n",
        "  print(f\"val_loss: {val_loss:3.4f}\")\n",
        "  val_loss_hist.append(val_loss)\n",
        "  total_loss = total_loss / steps_per_epoch\n",
        "  loss_hist.append(total_loss)\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 8999 samples : \n",
            "Epoch   1/10 :[==============================](100.00%)  time_elapsed (in s) : 826.11 loss : 2.49 val_loss: 2.3467\n",
            "Epoch   2/10 :[==============================](100.00%)  time_elapsed (in s) : 824.38 loss : 2.44 val_loss: 2.3165\n",
            "Epoch   3/10 :[==============================](100.00%)  time_elapsed (in s) : 828.68 loss : 2.40 val_loss: 2.2851\n",
            "Epoch   4/10 :[==============================](100.00%)  time_elapsed (in s) : 829.29 loss : 2.35 val_loss: 2.2505\n",
            "Epoch   5/10 :[==============================](100.00%)  time_elapsed (in s) : 828.58 loss : 2.31 val_loss: 2.2257\n",
            "Epoch   6/10 :[==============================](100.00%)  time_elapsed (in s) : 832.62 loss : 2.27 val_loss: 2.1887\n",
            "Epoch   7/10 :[==============================](100.00%)  time_elapsed (in s) : 851.33 loss : 2.22 val_loss: 2.1656\n",
            "Epoch   8/10 :[==============================](100.00%)  time_elapsed (in s) : 822.45 loss : 2.18 val_loss: 2.1541\n",
            "Epoch   9/10 :[==============================](100.00%)  time_elapsed (in s) : 826.16 loss : 2.15 val_loss: 2.1566\n",
            "Epoch  10/10 :[==============================](100.00%)  time_elapsed (in s) : 825.00 loss : 2.11 val_loss: 2.1475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP9xQBb1axwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(sample_size, epochs, loss_hist = [], val_hist = []):\n",
        "  print(f\"Training on {sample_size} samples : \")\n",
        "  for epoch in range(1, epochs+1):\n",
        "    start = time.time()\n",
        "    encoder_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    disp_loss = 0\n",
        "    val_loss = 0\n",
        "    batch_loss = 0\n",
        "    eta = np.inf\n",
        "    for batch, (inp, target) in enumerate(dataset.take(steps_per_epoch)):\n",
        "      batch_start = time.time()\n",
        "      elapsed = batch_start - start\n",
        "      at.progress_bar(f\"Epoch {epoch:3.0f}/{epochs} \", batch, steps_per_epoch, output_vals = {'eta(s)':eta, 'time_elapsed(s)':elapsed, 'loss':disp_loss}, jump_line = False)\n",
        "      batch_loss= train_step(inp, target, encoder_hidden)\n",
        "      total_loss += batch_loss\n",
        "      disp_loss = total_loss/(max(1, batch))\n",
        "      batch_elapsed = time.time()-batch_start\n",
        "      eta = (steps_per_epoch-(batch+1))*batch_elapsed\n",
        "    val_x, val_y = next(iter(val_dataset))\n",
        "    val_loss = batch_loss_func(val_y,val_x)\n",
        "    print(f\"val_loss: {val_loss:3.4f}\")\n",
        "    val_loss_hist.append(val_loss)\n",
        "    total_loss = total_loss / steps_per_epoch\n",
        "    loss_hist.append(total_loss)\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  return loss_hist, val_hist"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NhYc5tay62z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "02c9ed65-2df5-4209-b8bb-32cf1c7da5c7"
      },
      "source": [
        "loss_hist, val_loss_hist = fit_model(BUFFER_SIZE, 20, loss_hist, val_loss_hist)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 8999 samples : \n",
            "Epoch   1/20 :[==============================](100.00%)  eta(s) : 18.67 time_elapsed(s) : 830.36 loss : 2.09 val_loss: 2.1370\n",
            "Epoch   2/20 :[==============================](100.00%)  eta(s) : 18.95 time_elapsed(s) : 822.69 loss : 2.05 val_loss: 2.1409\n",
            "Epoch   3/20 :[==============================](100.00%)  eta(s) : 18.09 time_elapsed(s) : 830.62 loss : 2.02 val_loss: 2.1443\n",
            "Epoch   4/20 :[==============================](100.00%)  eta(s) : 19.75 time_elapsed(s) : 833.17 loss : 1.99 val_loss: 2.1558\n",
            "Epoch   5/20 :[==============================](100.00%)  eta(s) : 19.43 time_elapsed(s) : 844.68 loss : 1.95 val_loss: 2.1484\n",
            "Epoch   6/20 :[==============================](100.00%)  eta(s) : 19.11 time_elapsed(s) : 833.23 loss : 1.91 val_loss: 2.1559\n",
            "Epoch   7/20 :[==============================](100.00%)  eta(s) : 20.12 time_elapsed(s) : 827.76 loss : 1.88 val_loss: 2.1661\n",
            "Epoch   8/20 :[==============================](100.00%)  eta(s) : 19.23 time_elapsed(s) : 830.99 loss : 1.84 val_loss: 2.1804\n",
            "Epoch   9/20 :[==============================](100.00%)  eta(s) : 18.42 time_elapsed(s) : 839.46 loss : 1.79 val_loss: 2.1924\n",
            "Epoch  10/20 :[==============================](100.00%)  eta(s) : 19.02 time_elapsed(s) : 835.33 loss : 1.75 val_loss: 2.2030\n",
            "Epoch  11/20 :[==============================](100.00%)  eta(s) : 18.45 time_elapsed(s) : 823.68 loss : 1.71 val_loss: 2.2168\n",
            "Epoch  12/20 :[==============================](100.00%)  eta(s) : 19.33 time_elapsed(s) : 829.60 loss : 1.66 val_loss: 2.2330\n",
            "Epoch  13/20 :[==============================](100.00%)  eta(s) : 18.87 time_elapsed(s) : 823.36 loss : 1.61 val_loss: 2.2509\n",
            "Epoch  14/20 :[==============================](100.00%)  eta(s) : 19.20 time_elapsed(s) : 829.06 loss : 1.56 val_loss: 2.2739\n",
            "Epoch  15/20 :[==============================](100.00%)  eta(s) : 18.51 time_elapsed(s) : 826.72 loss : 1.51 val_loss: 2.3009\n",
            "Epoch  16/20 :[==============================](100.00%)  eta(s) : 18.07 time_elapsed(s) : 828.70 loss : 1.46 val_loss: 2.3110\n",
            "Epoch  17/20 :[==============================](100.00%)  eta(s) : 19.13 time_elapsed(s) : 828.13 loss : 1.40 val_loss: 2.3391\n",
            "Epoch  18/20 :[==============================](100.00%)  eta(s) : 19.11 time_elapsed(s) : 825.89 loss : 1.35 val_loss: 2.3619\n",
            "Epoch  19/20 :[==============================](100.00%)  eta(s) : 18.55 time_elapsed(s) : 833.69 loss : 1.29 val_loss: 2.3984\n",
            "Epoch  20/20 :[==============================](100.00%)  eta(s) : 18.53 time_elapsed(s) : 832.67 loss : 1.23 val_loss: 2.4194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qruJq4DiB4ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "bf6a4db5-08f5-407e-9a81-b03de73fecd1"
      },
      "source": [
        "plt.plot(loss_hist, label = 'loss')\n",
        "plt.plot(val_loss_hist, label = 'val_loss')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3dj2dVwElNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm -r \"/content/drive/My Drive/Colab Notebooks/topic_training_checkpoints\"\n",
        "echo \"removed all checkpoints\""
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "763n7AFcTMFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41a93f97-236c-4914-ffc6-b901d11a870e"
      },
      "source": [
        "print(\"Saving checkpoint at\", checkpoint.save(file_prefix = checkpoint_prefix))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving checkpoint at /content/drive/My Drive/Colab Notebooks/topic_training_checkpoints/ckpt-6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBefuv30-MM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length, max_length))\n",
        "\n",
        "  inputs = encode_texts([sentence])\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "\n",
        "  encoder_output, encoder_hidden, encoder_topic = encoder(inputs, hidden)\n",
        "\n",
        "  decoder_hidden = encoder_hidden\n",
        "  decoder_input = tf.expand_dims([word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length):\n",
        "    predictions, decoder_hidden, attention_weights = decoder(decoder_input, decoder_hidden, encoder_output, encoder_topic)\n",
        "\n",
        "    # Storing the attention weights to plot later\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "    # print(predictions.shape)\n",
        "    # input()\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += index_word[predicted_id]+' '\n",
        "\n",
        "    if index_word[predicted_id]=='<end>':\n",
        "      return result, sentence, attention_plot\n",
        "    \n",
        "    decoder_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot\n",
        "\n"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tznO-IWpB2nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting attention weights\n",
        "import matplotlib.ticker as ticker\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxeuR8fECIPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_response(sentence, plot_graph = False):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted Response: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  if plot_graph :plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D75uLkpwk75S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1badf053-ce16-4f2d-a97a-198fd13ed7f4"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctRHtNU-lBPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3637b321-867b-4fc0-bf51-92620f858ccd"
      },
      "source": [
        "checkpoint_dir"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/topic_training_checkpoints'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2BdLY05Dy33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e784c228-a19a-463b-9fe7-952a4d41b5e9"
      },
      "source": [
        "# Restore from last checkpoint \n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa8431f1780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTqjFrvNCj6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def argmax_beam(tensor, width):\n",
        "  arr = tensor.numpy()\n",
        "  assert arr.shape[0] == 1\n",
        "  arr_ = [c for c in arr[0]]\n",
        "  assert len(arr_) >= width, \"Beam width is greater than the tensor length\"\n",
        "  args = []\n",
        "  for i in range(width):\n",
        "    argm = np.argmax(arr_)\n",
        "    args.append(argm)\n",
        "    arr_[argm] = -np.inf\n",
        "  # print(args)\n",
        "  # input()\n",
        "  return args"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blF5rXTOEBFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "46777fa7-25e9-4c64-9232-0b3a671f5d64"
      },
      "source": [
        "a = np.random.randn(1, 5)\n",
        "print(a)\n",
        "a = tf.convert_to_tensor(a)\n",
        "b = np.random.randn(1, 5)\n",
        "print(b)\n",
        "b = tf.convert_to_tensor(b)\n",
        "# print([*argmax_beam(a, 3), *argmax_beam(b, 3)])\n",
        "c = tf.convert_to_tensor([[1, 2, 3]])\n",
        "print(argmax_beam(c, 2))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.71631729 -2.51801792  0.08257239 -0.40140944  0.65115605]]\n",
            "[[ 1.7934332  -1.5221072   2.91546638  0.01008598  0.50720946]]\n",
            "[2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3-kltX7Z9ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def beam_search_evaluate(sentence, beam_width=3, length_norm_alpha = 0.5):\n",
        "  inputs = encode_texts([sentence])\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  result = ['']*beam_width\n",
        "  results = []\n",
        "  scores_list = []\n",
        "  scores = [0]*beam_width\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  encoder_output, encoder_hidden, encoder_topic = encoder(inputs, hidden)\n",
        "  decoder_hidden = encoder_hidden\n",
        "  decoder_input = tf.expand_dims([word_index['<start>']], 0)\n",
        "  \n",
        "  # At t = 0\n",
        "  prediction, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output, encoder_topic)\n",
        "  ids = argmax_beam(prediction, beam_width)\n",
        "  predicted_id = []\n",
        "  for i, id in enumerate(ids):\n",
        "    result[i]+= index_word[id] + \" \"\n",
        "    predicted_id.append(id)\n",
        "  decoder_input = []\n",
        "  for i in range(beam_width) : \n",
        "      decoder_input.append(tf.expand_dims([predicted_id[i]], 0))\n",
        "  decoder_hidden = [decoder_hidden]*beam_width\n",
        "\n",
        "  # After t=0  \n",
        "  for t in range(1, max_length):\n",
        "    predictions = []\n",
        "    \n",
        "    for i in range(beam_width):\n",
        "      pred, decoder_hidden[i], _ = decoder(decoder_input[i], decoder_hidden[i], encoder_output, encoder_topic)\n",
        "      predictions.append(pred)\n",
        "    ids = [] # List of tuples : (id, predicted probability, decoder_hidden from beam)\n",
        "    \n",
        "    for beam in range(beam_width):\n",
        "      predicted_ids = argmax_beam(predictions[beam], beam_width)\n",
        "      for id in predicted_ids:\n",
        "        ids.append((id, predictions[beam][0,id],decoder_hidden[beam], result[beam])) \n",
        "    \n",
        "    probs = tf.convert_to_tensor([[i[1] for i in ids]])\n",
        "    best_id_indices = argmax_beam(probs, beam_width)\n",
        "    predicted_id = []\n",
        "\n",
        "    for i, idx in enumerate(best_id_indices):\n",
        "      pr_id, score, decoder_hidden[i], result[i] = ids[idx]\n",
        "      result[i] += index_word[pr_id] + \" \"\n",
        "      predicted_id.append(pr_id)\n",
        "      scores[i] = np.log(score.numpy())\n",
        "      \n",
        "\n",
        "    for i in range(beam_width):\n",
        "      if index_word[predicted_id[i]]=='<end>':        \n",
        "        results.append(result[i]) \n",
        "        # scores_list.append(scores[i])#*np.log(t))\n",
        "        \n",
        "    \n",
        "    if len(results) == beam_width:\n",
        "      return results, scores\n",
        "    \n",
        "    for i in range(beam_width) : \n",
        "      decoder_input[i] = tf.expand_dims([predicted_id[i]], 0)\n",
        "\n",
        "  return result, scores"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8okBPqPYcC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_response_beam(sentence, beam_width=3):\n",
        "  responses, scores = beam_search_evaluate(sentence, beam_width)\n",
        "  print(f\"Input : {sentence}\")\n",
        "  print(\"Responses\")\n",
        "  for r, s in zip(responses, scores):\n",
        "    print(r.split(\" <end>\")[0], \": Score = \", s)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5BkkKXt7Kby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4a053e3f-1c17-4f8a-98e9-6e26b2110392"
      },
      "source": [
        "get_response_beam(\"what happened?\")"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : what happened?\n",
            "Responses\n",
            "i know : Score =  1.4049828\n",
            "i think he knows : Score =  1.3604057\n",
            "i think he knows he knows : Score =  1.3112073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1txBoZH7Qun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "483a56ef-1434-4e6e-cecd-490fce0712a5"
      },
      "source": [
        "get_response(\"what happened?\")"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: what happened?\n",
            "Predicted Response: i don't a lame question <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnS986Mp-ll-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "def246c6-1b94-4bce-bae7-dad99307a064"
      },
      "source": [
        "get_response_beam(\"i got banned from the club's page\")"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : i got banned from the club's page\n",
            "Responses\n",
            "yeah : Score =  1.1494241\n",
            "being tailed : Score =  0.6611438\n",
            "no cameras : Score =  0.4718635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCRmkSq90-w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}